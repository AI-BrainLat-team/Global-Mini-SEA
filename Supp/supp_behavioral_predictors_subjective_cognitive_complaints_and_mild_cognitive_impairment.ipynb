{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7db7947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f44fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import plot_importance\n",
    "import plotly.graph_objects as go\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, f1_score, accuracy_score, recall_score, precision_score, confusion_matrix, mean_squared_error\n",
    "import seaborn as sns\n",
    "from statannot import add_stat_annotation\n",
    "from sklearn.linear_model import Lasso, MultiTaskLasso, Ridge, ElasticNet\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import mutual_info_regression, f_regression\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import time\n",
    "import scipy\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "\n",
    "from statsmodels.stats import multitest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7560232",
   "metadata": {},
   "source": [
    "## Biblioteca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f28081",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_color(var, X_cat_, color_dict_):\n",
    "\n",
    "    X_factors = list(X_cat_.factors)\n",
    "    X_name = list(X_cat_.newname)\n",
    "\n",
    "    index_code = X_name.index(var)\n",
    "    cat = X_factors[index_code]\n",
    "\n",
    "    return color_dict_[cat]\n",
    "\n",
    "color_dict = {}\n",
    "color_dict['Country'] = '#484849'\n",
    "color_dict['HF'] = '#A31300'\n",
    "color_dict['LSF'] = '#FF9E0D'\n",
    "color_dict['PSF'] = '#FF4800'\n",
    "color_dict['SDHF'] = '#1C4F9E'\n",
    "color_dict['DF'] = '#009E32'\n",
    "\n",
    "def get_bar_colors(data_, X_cat_):\n",
    "    color_dict = {}\n",
    "    color_dict['FP'] = '#111111'\n",
    "    color_dict['HF'] = '#A31300'\n",
    "    color_dict['FF1'] = '#FF9E0D'\n",
    "    color_dict['CF'] = '#FF4800'\n",
    "    color_dict['FF'] = '#1C4F9E'\n",
    "    color_dict['DF'] = '#009E32'\n",
    "    color_dict['FlairFL'] = '#DAEB07'\n",
    "    color_dict['FlairFR'] = '#EB9700'\n",
    "    color_dict['FlairF'] = '#FFD400'\n",
    "    color_dict['GMF'] = '#565E75'\n",
    "    \n",
    "    \n",
    "    #color_dict = {}\n",
    "    #color_dict = {'DF':'#5975a4', 'MF':'#cc8963', 'SF':'#5f9e6e', 'SLF':'#b55d60',\n",
    "    #              'n':'#857aab', 'country':'#8d7866'}#, '#d095bf'}\n",
    "\n",
    "    X_factors = list(X_cat_.factors)\n",
    "    X_name = list(X_cat_.name)\n",
    "\n",
    "    bar_color_total = []\n",
    "    for i in list(data_.Features):\n",
    "        if(i == 'Country'):\n",
    "            bar_color_total.append(color_dict['Country'])\n",
    "            continue\n",
    "        index_code = X_name.index(i)\n",
    "        cat = X_factors[index_code]\n",
    "        bar_color_total.append(color_dict[cat])\n",
    "    return bar_color_total\n",
    "\n",
    "\n",
    "def adj_r2_score_and_r2_score(clf, X, y):\n",
    "    n = X.shape[0]  # Number of observations\n",
    "    p = X.shape[1]  # Number of features\n",
    "    r_squared = r2_score(y, clf.predict(X))\n",
    "    return [1 - (1 - r_squared) * ((n - 1) / (n - p - 1)), r_squared]\n",
    "\n",
    "\n",
    "def mse(clf, X, y):\n",
    "    return mean_squared_error(y, clf.predict(X))\n",
    "\n",
    "def rmse(clf, X, y):\n",
    "    mse = mean_squared_error(y, clf.predict(X))\n",
    "    return math.sqrt(mse)    \n",
    "\n",
    "def coef_se(clf, X, y):\n",
    "    n = X.shape[0]\n",
    "    X1 = np.hstack((np.ones((n, 1)), np.matrix(X)))\n",
    "    se_matrix = scipy.linalg.sqrtm(\n",
    "        metrics.mean_squared_error(y, clf.predict(X)) *\n",
    "        np.linalg.inv(X1.T * X1)\n",
    "    )\n",
    "    return np.diagonal(se_matrix)\n",
    "\n",
    "def coef_tval(clf, X, y):\n",
    "    a = np.array(clf.intercept_ / coef_se(clf, X, y)[0])\n",
    "    b = np.array(clf.coef_ / coef_se(clf, X, y)[1:])\n",
    "    return np.append(a, b)\n",
    "\n",
    "def coef_tval_SVR_tree(clf, X, y):\n",
    "    a = np.array(clf.intercept_ / coef_se(clf, X, y)[0])\n",
    "    b = np.array(clf._get_coef() / coef_se(clf, X, y)[1:])\n",
    "    return np.append(a, b)\n",
    "\n",
    "def coef_pval(clf, X, y):\n",
    "\n",
    "    n = X.shape[0]\n",
    "    t = coef_tval(clf, X, y)\n",
    "    p = 2 * (1 - scipy.stats.t.cdf(abs(t), n - 1))\n",
    "    return p\n",
    "\n",
    "def coef_pval_SVR_tree(clf, X, y):\n",
    "\n",
    "    n = X.shape[0]\n",
    "    t = coef_tval_SVR_tree(clf, X, y)\n",
    "    p = 2 * (1 - scipy.stats.t.cdf(abs(t), n - 1))\n",
    "    return p\n",
    "\n",
    "def residuals(clf, X, y, r_type='standardized'):\n",
    "\n",
    "    # Make sure value of parameter 'r_type' is one we recognize\n",
    "    assert r_type in ('raw', 'standardized', 'studentized'), (\n",
    "        \"Invalid option for 'r_type': {0}\".format(r_type))\n",
    "    y_true = y.view(dtype='float')\n",
    "    # Use classifier to make predictions\n",
    "    y_pred = clf.predict(X)\n",
    "    # Make sure dimensions agree (Numpy still allows subtraction if they don't)\n",
    "    assert y_true.shape == y_pred.shape, (\n",
    "        \"Dimensions of y_true {0} do not match y_pred {1}\".format(y_true.shape,\n",
    "                                                                  y_pred.shape))\n",
    "    # Get raw residuals, or standardized or standardized residuals\n",
    "    resids = y_pred - y_true\n",
    "    if r_type == 'standardized':\n",
    "        resids = resids / np.std(resids)\n",
    "    elif r_type == 'studentized':\n",
    "        # Prepare a blank array to hold studentized residuals\n",
    "        studentized_resids = np.zeros(y_true.shape[0], dtype='float')\n",
    "        # Calcluate hat matrix of X values so you can get leverage scores\n",
    "        hat_matrix = np.dot(\n",
    "            np.dot(X, np.linalg.inv(np.dot(np.transpose(X), X))),\n",
    "            np.transpose(X))\n",
    "        # For each point, calculate studentized residuals w/ leave-one-out MSE\n",
    "        for i in range(y_true.shape[0]):\n",
    "            # Make a mask so you can calculate leave-one-out MSE\n",
    "            mask = np.ones(y_true.shape[0], dtype='bool')\n",
    "            mask[i] = 0\n",
    "            loo_mse = np.average(resids[mask] ** 2, axis=0)  # Leave-one-out MSE\n",
    "            # Calculate studentized residuals\n",
    "            studentized_resids[i] = resids[i] / np.sqrt(\n",
    "                loo_mse * (1 - hat_matrix[i, i]))\n",
    "        resids = studentized_resids\n",
    "    return resids\n",
    "\n",
    "\n",
    "def f_squared(clf, X, y):\n",
    "\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1]\n",
    "    r_squared = metrics.r2_score(y, clf.predict(X))\n",
    "    return r_squared  / (1 - r_squared)\n",
    "\n",
    "def f_stat(clf, X, y):\n",
    "    \"\"\"Calculate summary F-statistic for beta coefficients.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The F-statistic value.\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1]\n",
    "    r_squared = metrics.r2_score(y, clf.predict(X))\n",
    "    return (r_squared / p) / ((1 - r_squared) / (n - p - 1))\n",
    "\n",
    "\n",
    "def f_stat_pvalue(clf, X, y):\n",
    "    \"\"\"Calculate summary F-statistic p value for beta coefficients.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The F-statistic p value.\n",
    "    \"\"\"\n",
    "    n = X.shape[0] # Esto se extrae par los grados de libertad del numeador y el denomindor (no. predictores, no. sujetos - no. predictores-1)\n",
    "    p = X.shape[1]\n",
    "    r_squared = metrics.r2_score(y, clf.predict(X))\n",
    "    \n",
    "    return np.round(scipy.stats.f.sf(f_stat(clf, X, y), n, (n - p - 1)), 15)\n",
    "\n",
    "def compute_f_statistics(clf, X, y):\n",
    "    return [f_stat(clf, X, y), f_stat_pvalue(clf, X, y)]\n",
    "\n",
    "\n",
    "\n",
    "def boostrapping(X_func, case1A_func, case1A_func_for_strat, lista_best_func, model_ = SVR(kernel='rbf', degree=4), iter_total = 1000):\n",
    "    print(model_)\n",
    "    \n",
    "    coef_array_func = np.zeros([len(lista_best_func)+1, iter_total])\n",
    "    coef_t_value_func = np.zeros([len(lista_best_func)+1, iter_total])\n",
    "    coef_p_value_func = np.zeros([len(lista_best_func)+1, iter_total])\n",
    "\n",
    "    r2_list_func =[]\n",
    "    f2_list_func =[]\n",
    "    f_list_func =[]\n",
    "    f_p_value_list_func =[]\n",
    "    for iter in tqdm(range(0,iter_total), total=len(range(0, iter_total)),leave=True, mininterval=1, ascii=True,\n",
    "                            desc='Training model'):\n",
    "        # Stratified split\n",
    "        \n",
    "        finish = True\n",
    "        \n",
    "        while(finish):\n",
    "            \n",
    "            seed = np.random.randint(100, 200)\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_func, case1A_func, stratify=case1A_func_for_strat,test_size=0.30, random_state=seed)\n",
    "\n",
    "            model_func = model_\n",
    "\n",
    "            model_func.fit(X_train, y_train)\n",
    "\n",
    "            coef_array_func[0,iter] = np.abs(model_func.intercept_)\n",
    "            coef_array_func[1::,iter] = np.abs(model_func._get_coef())\n",
    "\n",
    "            try:\n",
    "\n",
    "                coef_t_value_func[:,iter] = np.round(np.abs(coef_tval_SVR_tree(model_func, X_test, y_test)), 30)\n",
    "                coef_p_value_func[:,iter] = np.round(np.abs(coef_pval_SVR_tree(model_func, X_test, y_test)), 30)\n",
    "\n",
    "\n",
    "                f2_list_func.append(f_squared(model_func, X_test, y_test))\n",
    "                f_list_func.append(f_stat(model_func, X_test, y_test))\n",
    "                f_p_value_list_func.append(f_stat_pvalue(model_func, X_test, y_test))\n",
    "                r2_list_func.append(r2_score(y_test, model_func.predict(X_test)))\n",
    "                finish = False\n",
    "            except:\n",
    "                finish = True\n",
    "\n",
    "\n",
    "    r2_list_array = np.array(r2_list_func)\n",
    "    # finding the 1st quartile\n",
    "    q1 = np.quantile(r2_list_array, 0.25)\n",
    " \n",
    "    # finding the 3rd quartile\n",
    "    q3 = np.quantile(r2_list_array, 0.75)\n",
    "    med = np.median(r2_list_array)\n",
    "\n",
    "    # finding the iqr region\n",
    "    iqr = q3-q1\n",
    "\n",
    "    # finding upper and lower whiskers\n",
    "    upper_bound = q3+(1.5*iqr)\n",
    "    lower_bound = q1-(1.5*iqr)\n",
    "    #print(iqr, upper_bound, lower_bound)\n",
    "\n",
    "    index_del = []     \n",
    "\n",
    "    for i in range(r2_list_array.shape[0]):\n",
    "        if((r2_list_array[i]<= lower_bound) | (r2_list_array[i] >= upper_bound)):\n",
    "            index_del.append(i)\n",
    "\n",
    "    \n",
    "    \n",
    "    r2_list_func = list(np.delete(r2_list_array,index_del, axis=0 ))\n",
    "\n",
    "    coef_df_func = pd.DataFrame(\n",
    "            index=['_intercept'] + lista_best_func,\n",
    "            columns=['Estimate','t value', 'p value', 'p value mean']\n",
    "        )\n",
    "\n",
    "    coef_array_func  = np.delete(coef_array_func,index_del, axis=1 )\n",
    "    coef_t_value_func = np.delete(coef_t_value_func,index_del, axis=1 )\n",
    "    coef_p_value_func = np.delete(coef_p_value_func,index_del, axis=1 )\n",
    "    \n",
    "    \n",
    "    coef_array_func_mean = np.zeros([len(lista_best_func)+1, 1])\n",
    "    coef_t_value_func_mean = np.zeros([len(lista_best_func)+1, 1])\n",
    "    coef_p_value_func_mean = np.zeros([len(lista_best_func)+1, 1])\n",
    "    coef_p_value_func_fdr = np.zeros([len(lista_best_func)+1, 1])\n",
    "    \n",
    "    coef_array_func_std = np.zeros([len(lista_best_func)+1, 1])\n",
    "\n",
    "    print('shape',coef_array_func.shape, coef_t_value_func.shape, coef_p_value_func.shape, len(index_del))\n",
    "    \n",
    "    for i in range(len(lista_best_func)+1):\n",
    "        coef_array_func_mean[i] = coef_array_func[i,:].mean()\n",
    "        coef_t_value_func_mean[i]= coef_t_value_func[i,:].mean()\n",
    "        coef_p_value_func_mean[i]= coef_p_value_func[i,:].mean()\n",
    "        coef_p_value_func_fdr[i]= fdrcorrection(coef_p_value_func[i,:], alpha=0.05, is_sorted=False )[1].max()\n",
    "        \n",
    "        coef_array_func_std[i] = coef_array_func[i,:].std()\n",
    "        # Se corrige por FDR y se reporta el valor máximo\n",
    "\n",
    "    coef_df_func['Estimate'] = coef_array_func_mean\n",
    "    coef_df_func['t value'] = coef_t_value_func_mean\n",
    "    coef_df_func['p value'] = coef_p_value_func_fdr\n",
    "    coef_df_func['p value mean'] = coef_p_value_func_mean\n",
    "    coef_df_func['Estimate std'] = coef_array_func_std\n",
    "\n",
    "\n",
    "    empty_str = []\n",
    "    for i in range(coef_df_func.shape[0]):\n",
    "        empty_str.append('')\n",
    "\n",
    "    coef_df_func['value'] = empty_str\n",
    "\n",
    "    coef_df_func = coef_df_func.T\n",
    "    coef_df_func['R-squared'] = ['','','','', '', np.mean(r2_list_func)]\n",
    "    coef_df_func['CI'] = ['','','','', '', np.std(r2_list_func)*1.96]\n",
    "    coef_df_func['F-squared'] = ['','','','', '', np.mean(f2_list_func)]\n",
    "    coef_df_func['F'] = ['','','','', '', np.mean(f_list_func)]\n",
    "    \n",
    "    \n",
    "    pvalue_limit = 1e-300\n",
    "\n",
    "    # Ajusta valores p que son menores que el límite\n",
    "    adjusted_pvalues = [p if p > pvalue_limit else pvalue_limit for p in fdrcorrection(f_p_value_list_func, alpha=0.05, method='indep', is_sorted=False )[1]]\n",
    "    from scipy.stats import combine_pvalues\n",
    "    \n",
    "    \n",
    "    coef_df_func['F-pvalue'] = ['','','','', '', combine_pvalues(adjusted_pvalues, method='fisher')[1]]\n",
    "    \n",
    "    #coef_df_func['F-pvalue_fdr'] = ['','','', fdrcorrection(f_p_value_list_func, alpha=0.05, method='indep', is_sorted=False )]\n",
    "    coef_df_func = coef_df_func.T\n",
    "\n",
    "\n",
    "    print(np.mean(r2_list_func),  np.std(r2_list_func)*1.96)\n",
    "    \n",
    "    return [coef_df_func, r2_list_func, f_p_value_list_func, fdrcorrection(f_p_value_list_func, alpha=0.05, is_sorted=False )]\n",
    "\n",
    "\n",
    "def plot_estimate_value(regression_model, X_cat_ = [], title = '',  xlim =[0, 2] ,fig_size = (8,12), size = 12, pvalue_type = 'False', plot_ci = ''):\n",
    "\n",
    "    df = regression_model\n",
    "    df.index.name = 'Features'\n",
    "    df = df.iloc[1:-5, 0:-1]\n",
    "\n",
    "    for i in range(3):\n",
    "            #print(i, X_RAW_edu_level[X_RAW_edu_level.columns[i]].dtype)\n",
    "        df[df.columns[i]] = np.abs(pd.to_numeric(df[df.columns[i]],errors = 'coerce'))\n",
    "\n",
    "    df = df.reset_index()\n",
    "    data = df.sort_values('Estimate', ascending=False)\n",
    "\n",
    "    \n",
    "    if(len(X_cat_)>0):\n",
    "        \n",
    "        bar_color = get_bar_colors(data, X_cat_)\n",
    "        \n",
    "        plt.title(title)\n",
    "        sns.barplot(x=\"Estimate\", y=\"Features\", data = data, xerr=data['Estimate std'], palette =bar_color)\n",
    "        plt.xlim(xlim)\n",
    "    else:\n",
    "        plt.title(title)\n",
    "        sns.barplot(x=\"Estimate\", y=\"Features\", data = data, color = 'darkblue')\n",
    "        plt.xlim(xlim)\n",
    "\n",
    "\n",
    "    y_step=0  \n",
    "    for i in range(df.shape[0]):\n",
    "        if(np.round(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step],3)<=0.01):\n",
    "            color = 'green'\n",
    "        elif(np.round(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step],3)<=0.05):\n",
    "            color = 'gray'\n",
    "        else:\n",
    "            color = 'red'        \n",
    "        \n",
    "        if(pvalue_type == 'color'):\n",
    "                plt.text(df.sort_values('Estimate', ascending=False)['Estimate'].iloc[y_step]-0.005, y_step, \n",
    "                                 '' + str(np.round(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step],2)),\n",
    "                                 size= size, rotation=0.,\n",
    "                                 ha=\"left\", va=\"center\", color = 'white',\n",
    "                                 bbox=dict(boxstyle=\"round\",\n",
    "                                           ec=color,\n",
    "                                            fc=color,\n",
    "                                           )\n",
    "                                 )\n",
    "                y_step+=1\n",
    "\n",
    "        elif(pvalue_type == 'value'):\n",
    "                plt.text(df.sort_values('Estimate', ascending=False)['Estimate'].iloc[y_step]+0.005, y_step, \n",
    "                                 '(' + str(np.round(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step],8))+')',\n",
    "                                 size= size, rotation=0.,\n",
    "                                 ha=\"left\", va=\"center\", color = 'black',\n",
    "\n",
    "                                 )\n",
    "                y_step+=1\n",
    "        else:\n",
    "            \n",
    "            if(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step]<0.01):\n",
    "                \n",
    "                    plt.text(df.sort_values('Estimate', ascending=False)['Estimate'].iloc[y_step]+0.005, y_step, \n",
    "                                     '**',\n",
    "                                     size= size, rotation=0.,\n",
    "                                     ha=\"left\", va=\"center\", color = 'black',\n",
    "\n",
    "                                     )\n",
    "            elif(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step]>= 0.01 and df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step]<0.05):\n",
    "                  \n",
    "                    plt.text(df.sort_values('Estimate', ascending=False)['Estimate'].iloc[y_step]+0.005, y_step, \n",
    "                                     '*',\n",
    "                                     size= size, rotation=0.,\n",
    "                                     ha=\"left\", va=\"center\", color = 'black',\n",
    "\n",
    "                                     )  \n",
    "            else:\n",
    "                    plt.text(df.sort_values('Estimate', ascending=False)['Estimate'].iloc[y_step]+0.005, y_step, \n",
    "                                     ' ',\n",
    "                                     size= size, rotation=0.,\n",
    "                                     ha=\"left\", va=\"center\", color = 'black',\n",
    "\n",
    "                                     )    \n",
    "\n",
    "            y_step+=1\n",
    "            \n",
    "         \n",
    "    text_diff =xlim[1]\n",
    "    #coef_SVR_tot.loc['R-squared', 'value']\n",
    "    f_prob = '(ns)'\n",
    "    if(regression_model.loc['F-pvalue', 'value']<0.01):\n",
    "        f_prob = '(**)'\n",
    "    elif(regression_model.loc['F-pvalue', 'value']<0.05):\n",
    "        f_prob = '(*)'\n",
    "        \n",
    "    \n",
    "    plot_ci = np.round(regression_model.loc['CI', 'value'],2)\n",
    "    \n",
    "    plt.text(xlim[1] - 0.05*xlim[1], df.shape[0]- 0.25*df.shape[0],\n",
    "             r'$ R^2 = $' + str(np.round(regression_model.loc['R-squared', 'value'],2))+ '\\n$CI = $' + str(plot_ci) + '\\n$F^2 = $' + str(np.round(regression_model.loc['F-squared', 'value'],2)) + ' ' + '\\n$F = $' + str(np.round(regression_model.loc['F', 'value'],2)) + '\\n$P (F) = $' + f_prob,\n",
    "                             size= 12, rotation=0.,\n",
    "                             ha=\"right\", va=\"center\", color = 'black',\n",
    "                             bbox=dict(boxstyle=\"round\",\n",
    "                                       ec='gray',\n",
    "                                        fc='gray',\n",
    "                                       )\n",
    "                             )\n",
    "\n",
    "    plt.xticks(fontsize=10)\n",
    "    plt.yticks(fontsize=10)\n",
    "    \n",
    "    plt.xlabel('Estimate', fontsize=12)\n",
    "    plt.ylabel('Features', fontsize=12)\n",
    "    plt.locator_params(axis='x', nbins=4)\n",
    "    \n",
    "\n",
    "def plot_evolution(dict_Df, i, X_cat_, xlim = [0,25], size = 10):\n",
    "\n",
    "    fp_value = dict_Df[i][1]\n",
    "    fp_value_fdr = dict_Df[i][2]\n",
    "    coef_df_ = dict_Df[i][0]\n",
    "\n",
    "\n",
    "    title = 'iter:' + str(i) + '\\n'\n",
    "    title += '|    f-pva: (' + str(np.min(fp_value).round(3)) + ' ; ' + str(np.mean(fp_value).round(3)) + ' ; ' + str(np.max(fp_value).round(3)) + ' ; ' + str(np.median(fp_value).round(3)) + ') |\\n'\n",
    "    title += '|  fdr-pva: (' + str(np.min(fp_value_fdr).round(3)) + ' ; ' + str(np.mean(fp_value_fdr).round(3)) + ' ; ' + str(np.max(fp_value_fdr).round(3)) + ' ; ' + str(np.median(fp_value_fdr).round(3)) + ') |'\n",
    "\n",
    "\n",
    "\n",
    "    coef_df_ = coef_df_.sort_values('Estimate', ascending=False)\n",
    "    \n",
    "    bar_color = get_bar_colors(coef_df_, X_cat_)\n",
    "    plt.title(title)\n",
    "    sns.barplot(x=\"Estimate\", y=\"Features\", data = coef_df_, xerr=coef_df_['Estimate std'], palette =bar_color)\n",
    "    plt.xlim(xlim);\n",
    "\n",
    "    y_step=0 \n",
    "    for j in range(coef_df_.shape[0]):\n",
    "        if(coef_df_['p value'].iloc[y_step]<0.01):\n",
    "\n",
    "            plt.text(coef_df_['Estimate'].iloc[y_step]+0.005, y_step, \n",
    "                                             '**',\n",
    "                                             size= size, rotation=0.,\n",
    "                                             ha=\"left\", va=\"center\", color = 'black',\n",
    "\n",
    "                                             )\n",
    "        elif(coef_df_['p value'].iloc[y_step]>= 0.01 and df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step]<0.05):\n",
    "\n",
    "            plt.text(coef_df_['Estimate'].iloc[y_step]+0.005, y_step, \n",
    "                                             '*',\n",
    "                                             size= size, rotation=0.,\n",
    "                                             ha=\"left\", va=\"center\", color = 'black',\n",
    "\n",
    "                                             )  \n",
    "        else:\n",
    "            plt.text(coef_df_['Estimate'].iloc[y_step]+0.005, y_step, \n",
    "                                             ' ',\n",
    "                                             size= size, rotation=0.,\n",
    "                                             ha=\"left\", va=\"center\", color = 'black',\n",
    "\n",
    "                                             )    \n",
    "\n",
    "        y_step+=1\n",
    "        \n",
    "        \n",
    "    \n",
    "def SearchBestModel(case_x, case_y, case_x_for_strat):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(case_x, case_y, test_size=.30, stratify=case_x_for_strat, random_state=1)\n",
    "\n",
    "    opt_SVR = BayesSearchCV(\n",
    "            SVR(),\n",
    "            {\n",
    "                #'gamma': ( 0.0001, 0.01, 0.001, 0.1, 1, 10),\n",
    "                'kernel': ['rbf'],\n",
    "                'degree': (3, 4, 5, 6),\n",
    "                #'tol:' : (1e-6, 1e-3, 1e+1),\n",
    "                #'n_estimators': (100, 1000),\n",
    "\n",
    "            },\n",
    "            n_iter=10,\n",
    "            cv=3, random_state=1\n",
    "        )\n",
    "\n",
    "    opt_SVR.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    print('SVR')\n",
    "    print(\"val. score: %s\" % opt_SVR.best_score_)\n",
    "    print(\"test score: %s\" % opt_SVR.score(X_test, y_test))\n",
    "    print(\"best parameters: %s\" % str(opt_SVR.best_params_))\n",
    "    print('---------------------------------------------\\n')\n",
    "    \n",
    "    return opt_SVR\n",
    "\n",
    "def all_process(conn_z_score_fer, conn_z_score_tom, conn_z_score_tot, iter_tot = 1000, model_name = '', best_ = '', xl = 80):\n",
    "\n",
    "    ## y data\n",
    "    y_2A_fer = conn_z_score_fer['mini_sea_fer']\n",
    "    y_2A_tom = conn_z_score_tom['mini_sea_tom']\n",
    "    y_2A_tot = conn_z_score_tot['mini_sea_total']\n",
    "\n",
    "\n",
    "\n",
    "    ## x data\n",
    "    X_2A_fer = conn_z_score_fer.drop(['mini_sea_fer'], axis =1)\n",
    "    X_2A_tom = conn_z_score_tom.drop(['mini_sea_tom'], axis =1)\n",
    "    X_2A_tot = conn_z_score_tot.drop(['mini_sea_total'], axis =1)\n",
    "\n",
    "\n",
    "    best_w_cog = list(best_)\n",
    "    #best_w_cog.extend(['Edad_procesada', 'years_education', 'diagnosis_specify', 'country_class','cognition_general_score', 'executive_score'])#, 'gender'])\n",
    "    best_w_cog = np.array(best_w_cog)\n",
    "    \n",
    "    #print(best_w_cog)\n",
    "\n",
    "\n",
    "    X_2A_fer = X_2A_fer[best_w_cog]\n",
    "    X_2A_tom = X_2A_tom[best_w_cog]\n",
    "    X_2A_tot = X_2A_tot[best_w_cog]\n",
    "    \n",
    "    case2A_fer_for_strat =  y_2A_fer.copy()\n",
    "    median = case2A_fer_for_strat.median()\n",
    "    case2A_fer_for_strat.loc[case2A_fer_for_strat<median]= 0\n",
    "    case2A_fer_for_strat.loc[case2A_fer_for_strat>=median]=1 \n",
    "    \n",
    "    case2A_tom_for_strat =  y_2A_tom.copy()\n",
    "    median = case2A_tom_for_strat.median()\n",
    "    case2A_tom_for_strat.loc[case2A_tom_for_strat<median]= 0\n",
    "    case2A_tom_for_strat.loc[case2A_tom_for_strat>=median]=1 \n",
    "\n",
    "    case2A_tot_for_strat =  y_2A_tot.copy()\n",
    "    median = case2A_tot_for_strat.median()\n",
    "    case2A_tot_for_strat.loc[case2A_tot_for_strat<median]= 0\n",
    "    case2A_tot_for_strat.loc[case2A_tot_for_strat>=median]=1 \n",
    "    \n",
    "    # Boostsrapping fer\n",
    "    \n",
    "    X_2A_fer_classic_reg = X_2A_fer\n",
    "\n",
    "    run = True\n",
    "\n",
    "    coef_SVR_fer_dir_2A = {}\n",
    "\n",
    "\n",
    "    run_count = 0\n",
    "    while run:\n",
    "        coef_SVR_fer = boostrapping(X_2A_fer_classic_reg, y_2A_fer, case2A_fer_for_strat, list(X_2A_fer_classic_reg.columns), iter_total=iter_tot)\n",
    "\n",
    "        coef_SVR_fer_dir_2A[run_count] = coef_SVR_fer\n",
    "\n",
    "        run_count+=1\n",
    "\n",
    "        df = coef_SVR_fer[0]\n",
    "        df.index.name = 'Features'\n",
    "        df = df.iloc[1:-5, 0:-1]\n",
    "\n",
    "        df = df.reset_index()\n",
    "        data = df.sort_values('p value', ascending=False)\n",
    "        data\n",
    "\n",
    "        feat_remove = data.iloc[0,0]\n",
    "\n",
    "        if(X_2A_fer_classic_reg.shape[1]<=8 or data.iloc[0,3] < 0.05 or coef_SVR_fer[0].loc['F-pvalue', 'value'] < 0.05):\n",
    "            run = False\n",
    "        else:\n",
    "            X_2A_fer_classic_reg = X_2A_fer_classic_reg.drop([feat_remove], axis=1)\n",
    "            print(feat_remove)\n",
    "            \n",
    "            \n",
    "    # Boostsrapping tom\n",
    "        \n",
    "    X_2A_tom_classic_reg = X_2A_tom\n",
    "\n",
    "    run = True\n",
    "\n",
    "    coef_SVR_tom_dir_2A = {}\n",
    "\n",
    "\n",
    "    run_count = 0\n",
    "    while run:\n",
    "        coef_SVR_tom = boostrapping(X_2A_tom_classic_reg, y_2A_tom, case2A_tom_for_strat, list(X_2A_tom_classic_reg.columns), iter_total=iter_tot)\n",
    "\n",
    "        coef_SVR_tom_dir_2A[run_count] = coef_SVR_tom\n",
    "\n",
    "        run_count+=1\n",
    "\n",
    "        df = coef_SVR_tom[0]\n",
    "        df.index.name = 'Features'\n",
    "        df = df.iloc[1:-5, 0:-1]\n",
    "\n",
    "        df = df.reset_index()\n",
    "        data = df.sort_values('p value', ascending=False)\n",
    "        data\n",
    "\n",
    "        feat_remove = data.iloc[0,0]\n",
    "\n",
    "        if(X_2A_tom_classic_reg.shape[1]<=8 or data.iloc[0,3] < 0.05 or coef_SVR_tom[0].loc['F-pvalue', 'value'] < 0.05):\n",
    "            run = False\n",
    "        else:\n",
    "            X_2A_tom_classic_reg = X_2A_tom_classic_reg.drop([feat_remove], axis=1)\n",
    "            print(feat_remove)\n",
    "            \n",
    "     # Boostsrapping tot\n",
    "    X_2A_tot_classic_reg = X_2A_tot\n",
    "\n",
    "    run = True\n",
    "\n",
    "    coef_SVR_tot_dir_2A = {}\n",
    "\n",
    "\n",
    "    run_count = 0\n",
    "    while run:\n",
    "        coef_SVR_tot = boostrapping(X_2A_tot_classic_reg, y_2A_tot, case2A_tot_for_strat, list(X_2A_tot_classic_reg.columns), iter_total=iter_tot)\n",
    "\n",
    "        coef_SVR_tot_dir_2A[run_count] = coef_SVR_tot\n",
    "\n",
    "        run_count+=1\n",
    "\n",
    "        df = coef_SVR_tot[0]\n",
    "        df.index.name = 'Features'\n",
    "        df = df.iloc[1:-5, 0:-1]\n",
    "\n",
    "        df = df.reset_index()\n",
    "        data = df.sort_values('p value', ascending=False)\n",
    "        data\n",
    "\n",
    "        feat_remove = data.iloc[0,0]\n",
    "\n",
    "        if(X_2A_tot_classic_reg.shape[1]<=8 or data.iloc[0,3] < 0.05 or data.iloc[0,3] < 0.05 or coef_SVR_tot[0].loc['F-pvalue', 'value'] < 0.01):\n",
    "            run = False\n",
    "        else:\n",
    "            X_2A_tot_classic_reg = X_2A_tot_classic_reg.drop([feat_remove], axis=1)\n",
    "            print(feat_remove)\n",
    "            \n",
    "    fer_2A_keys = list(coef_SVR_fer_dir_2A.keys())\n",
    "    tom_2A_keys = list(coef_SVR_tom_dir_2A.keys())\n",
    "    tot_2A_keys = list(coef_SVR_tot_dir_2A.keys())\n",
    "\n",
    "    \n",
    "\n",
    "    plt.figure(figsize=(13,10))\n",
    "    grid = plt.GridSpec(2, 3)\n",
    "\n",
    "    plt.subplot(grid[0, 0])\n",
    "    plot_estimate_value(coef_SVR_fer_dir_2A[fer_2A_keys[-1]][0], X_cat, title = 'SVR fer (' + str(X_2A_fer_classic_reg.shape[0]) + ')',  xlim =[0, xl])\n",
    "    plt.subplot(grid[0, 1])\n",
    "    plot_estimate_value(coef_SVR_tom_dir_2A[tom_2A_keys[-1]][0], X_cat, title = 'SVR tom (' + str(X_2A_tom_classic_reg.shape[0]) + ')',  xlim =[0, xl])\n",
    "    plt.subplot(grid[0, 2])\n",
    "    plot_estimate_value(coef_SVR_tot_dir_2A[tot_2A_keys[-1]][0], X_cat, title = 'SVR tot (' + str(X_2A_tot_classic_reg.shape[0]) + ')',  xlim =[0, xl])\n",
    "\n",
    "    boxplots = []\n",
    "    boxplots.append(coef_SVR_fer_dir_2A[fer_2A_keys[-1]][1])\n",
    "    boxplots.append(coef_SVR_tom_dir_2A[tom_2A_keys[-1]][1])\n",
    "    boxplots.append(coef_SVR_tot_dir_2A[tot_2A_keys[-1]][1])\n",
    "\n",
    "\n",
    "\n",
    "    plt.subplot(grid[1, :])\n",
    "    plt.boxplot(boxplots);\n",
    "    plt.xticks(list(range(1,4)), ['fer', 'tom', 'tot'], rotation = 45);\n",
    "    plt.ylabel('R2')\n",
    "    plt.xlabel('Outcomes')\n",
    "\n",
    "    plt.tight_layout(pad=2);\n",
    "    \n",
    "    #plt.savefig('figures/' + model_name +'.pdf', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "     \n",
    "    coef_SVR_fer_dir_2A[fer_2A_keys[-1]][0].to_excel('results/'+model_name+'_fer.xlsx')\n",
    "    coef_SVR_tom_dir_2A[tom_2A_keys[-1]][0].to_excel('results/'+model_name+'_tom.xlsx')\n",
    "    coef_SVR_tot_dir_2A[tot_2A_keys[-1]][0].to_excel('results/'+model_name+'_tot.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582301b8",
   "metadata": {},
   "source": [
    "### Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1f6251",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_z_score = pd.read_excel('../Data/Base.xlsx', index_col=0)\n",
    "X_cat = pd.read_csv('../Data/var_name_color_code.csv', encoding='latin-1', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b395415",
   "metadata": {},
   "outputs": [],
   "source": [
    "#colunm = 'diagnosis_specify'\n",
    "#cn_col = conn_z_score[colunm]\n",
    "\n",
    "#conn_z_score[colunm] = conn_z_score[colunm].apply(lambda x: (x-cn_col.mean())/ cn_col.std())\n",
    "\n",
    "\n",
    "colunm = 'country_class'\n",
    "cn_col = conn_z_score[colunm]\n",
    "\n",
    "conn_z_score[colunm] = conn_z_score[colunm].apply(lambda x: (x-cn_col.mean())/ cn_col.std())\n",
    "\n",
    "\n",
    "\n",
    "colunm = 'Edad_procesada'\n",
    "cn_col = conn_z_score[colunm]\n",
    "\n",
    "conn_z_score[colunm] = conn_z_score[colunm].apply(lambda x: (x-cn_col.mean())/ cn_col.std())\n",
    "\n",
    "\n",
    "\n",
    "colunm = 'years_education'\n",
    "cn_col = conn_z_score[colunm]\n",
    "\n",
    "conn_z_score[colunm] = conn_z_score[colunm].apply(lambda x: (x-cn_col.mean())/ cn_col.std())\n",
    "\n",
    "\n",
    "colunm = 'cognition_general_score'\n",
    "cn_col = conn_z_score[colunm]\n",
    "\n",
    "conn_z_score[colunm] = conn_z_score[colunm].apply(lambda x: (x-cn_col.mean())/ cn_col.std())\n",
    "\n",
    "\n",
    "\n",
    "colunm = 'executive_score'\n",
    "cn_col = conn_z_score[colunm]\n",
    "\n",
    "conn_z_score[colunm] = conn_z_score[colunm].apply(lambda x: (x-cn_col.mean())/ cn_col.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff54282",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_z_score = conn_z_score.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5181bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_z_score.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691a0d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_z_score.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39519e9e",
   "metadata": {},
   "source": [
    "## Bulletpoint 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bff4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = ['gender', 'Edad_procesada',\n",
    "       'years_education', 'cognition_general_score', 'executive_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8900542",
   "metadata": {},
   "outputs": [],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2181565d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_z_score_qcs_dcl = conn_z_score[(conn_z_score['diagnosis_specify']==4 ) | (conn_z_score['diagnosis_specify']==5.000000000000001)]\n",
    "conn_z_score_qcs_dcl.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6079b390",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_qcs_dcl_fer = conn_z_score_qcs_dcl.drop([              'mini_sea_tom', 'mini_sea_total'], axis =1 )\n",
    "sex_qcs_dcl_tom = conn_z_score_qcs_dcl.drop(['mini_sea_fer',                 'mini_sea_total'], axis =1 )\n",
    "sex_qcs_dcl_tot = conn_z_score_qcs_dcl.drop(['mini_sea_fer', 'mini_sea_tom',                 ], axis =1 )\n",
    "\n",
    "sex_qcs_dcl_fer.dropna(inplace=True)\n",
    "sex_qcs_dcl_tom.dropna(inplace=True)  \n",
    "sex_qcs_dcl_tot.dropna(inplace=True) \n",
    "\n",
    "print(sex_qcs_dcl_fer.shape,\n",
    "sex_qcs_dcl_tom.shape,  \n",
    "sex_qcs_dcl_tot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6785dea9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_process(sex_qcs_dcl_fer, sex_qcs_dcl_tom, sex_qcs_dcl_tot, iter_tot = 100, model_name = '', best_=best, xl = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b128251d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d78497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260ff123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b5dbe2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "375.199px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
