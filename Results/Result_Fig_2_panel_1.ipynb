{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import plot_importance\n",
    "import plotly.graph_objects as go\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, f1_score, accuracy_score, recall_score, precision_score, confusion_matrix, mean_squared_error\n",
    "import seaborn as sns\n",
    "from statannot import add_stat_annotation\n",
    "from sklearn.linear_model import Lasso, MultiTaskLasso, Ridge, ElasticNet\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import mutual_info_regression, f_regression\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import time\n",
    "\n",
    "import scipy\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "\n",
    "from statsmodels.stats import multitest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color(var, X_cat_, color_dict_):\n",
    "\n",
    "    X_factors = list(X_cat_.factors)\n",
    "    X_name = list(X_cat_.newname)\n",
    "\n",
    "    index_code = X_name.index(var)\n",
    "    cat = X_factors[index_code]\n",
    "\n",
    "    return color_dict_[cat]\n",
    "\n",
    "\n",
    "def get_bar_colors(data_, X_cat_):\n",
    "    color_dict = {}\n",
    "    color_dict['FP'] = '#FAF85F'\n",
    "    color_dict['HF'] = '#cc8963' #b55d60\n",
    "    color_dict['FF1'] = '#FF9E0D'\n",
    "    color_dict['CF'] = '#b55d60' #cc8963\n",
    "    color_dict['FF'] = '#5975a4'\n",
    "    color_dict['DF'] = '#5f9e6e'\n",
    "    color_dict['FlairFL'] = '#DAEB07'\n",
    "    color_dict['FlairFR'] = '#EB9700'\n",
    "    color_dict['FlairF'] = '#FFD400'\n",
    "    color_dict['GMF'] = '#757575'\n",
    "    color_dict['WMF'] = '#DADEE0'\n",
    "\n",
    "    X_factors = list(X_cat_.factors)\n",
    "    X_name = list(X_cat_.name)\n",
    "\n",
    "    bar_color_total = []\n",
    "    for i in list(data_.Features):\n",
    "        if(i == 'Country'):\n",
    "            bar_color_total.append(color_dict['Country'])\n",
    "            continue\n",
    "        index_code = X_name.index(i)\n",
    "        cat = X_factors[index_code]\n",
    "        bar_color_total.append(color_dict[cat])\n",
    "    return bar_color_total\n",
    "\n",
    "\n",
    "\n",
    "def plot_estimate_value_v1(regression_model, X_cat_ = [], title = '',  xlim =[0, 2] ,fig_size = (8,12), size = 12, pvalue_type = 'False', plot_ci = '', report_pos = [50, 4], n = 10):\n",
    "\n",
    "    df = regression_model\n",
    "    df.index.name = 'Features'\n",
    "    df = df.iloc[1:-5, 0:-1]\n",
    "\n",
    "    for i in range(3):\n",
    "            #print(i, X_RAW_edu_level[X_RAW_edu_level.columns[i]].dtype)\n",
    "        df[df.columns[i]] = np.abs(pd.to_numeric(df[df.columns[i]],errors = 'coerce'))\n",
    "\n",
    "    df = df.reset_index()\n",
    "    data = df.sort_values('Estimate', ascending=False)\n",
    "\n",
    "    \n",
    "    if(len(X_cat_)>0):\n",
    "        \n",
    "        bar_color = get_bar_colors(data, X_cat_)\n",
    "        \n",
    "        plt.title(title)\n",
    "        sns.barplot(x=\"Estimate\", y=\"Features\", data = data, xerr=data['Estimate std'], palette =bar_color)\n",
    "        plt.xlim(xlim)\n",
    "    else:\n",
    "        plt.title(title)\n",
    "        sns.barplot(x=\"Estimate\", y=\"Features\", data = data, color = 'darkblue')\n",
    "        plt.xlim(xlim)\n",
    "\n",
    "\n",
    "    y_step=0  \n",
    "    for i in range(df.shape[0]):\n",
    "        if(np.round(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step],3)<=0.01):\n",
    "            color = 'green'\n",
    "        elif(np.round(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step],3)<=0.05):\n",
    "            color = 'gray'\n",
    "        else:\n",
    "            color = 'red'        \n",
    "        \n",
    "        if(pvalue_type == 'color'):\n",
    "                plt.text(df.sort_values('Estimate', ascending=False)['Estimate'].iloc[y_step]-0.005, y_step, \n",
    "                                 '' + str(np.round(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step],2)),\n",
    "                                 size= size, rotation=0.,\n",
    "                                 ha=\"left\", va=\"center\", color = 'white',\n",
    "                                 bbox=dict(boxstyle=\"round\",\n",
    "                                           ec=color,\n",
    "                                            fc=color,\n",
    "                                           )\n",
    "                                 )\n",
    "                y_step+=1\n",
    "\n",
    "        elif(pvalue_type == 'value'):\n",
    "                plt.text(df.sort_values('Estimate', ascending=False)['Estimate'].iloc[y_step]+0.005, y_step, \n",
    "                                 '(' + str(np.round(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step],8))+')',\n",
    "                                 size= size, rotation=0.,\n",
    "                                 ha=\"left\", va=\"center\", color = 'black',\n",
    "\n",
    "                                 )\n",
    "                y_step+=1\n",
    "        else:\n",
    "            \n",
    "            if(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step]<0.01):\n",
    "                \n",
    "                    plt.text(df.sort_values('Estimate', ascending=False)['Estimate'].iloc[y_step]+0.005, y_step, \n",
    "                                     '**',\n",
    "                                     size= size, rotation=0.,\n",
    "                                     ha=\"left\", va=\"center\", color = 'black',\n",
    "\n",
    "                                     )\n",
    "            elif(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step]>= 0.01 and df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step]<0.05):\n",
    "                  \n",
    "                    plt.text(df.sort_values('Estimate', ascending=False)['Estimate'].iloc[y_step]+0.005, y_step, \n",
    "                                     '*',\n",
    "                                     size= size, rotation=0.,\n",
    "                                     ha=\"left\", va=\"center\", color = 'black',\n",
    "\n",
    "                                     )  \n",
    "            else:\n",
    "                    plt.text(df.sort_values('Estimate', ascending=False)['Estimate'].iloc[y_step]+0.005, y_step, \n",
    "                                     ' ',\n",
    "                                     size= size, rotation=0.,\n",
    "                                     ha=\"left\", va=\"center\", color = 'black',\n",
    "\n",
    "                                     )    \n",
    "\n",
    "            y_step+=1\n",
    "            \n",
    "         \n",
    "    text_diff =xlim[1]\n",
    "    #coef_SVR_tot.loc['R-squared', 'value']\n",
    "    f_prob = '(ns)'\n",
    "    if(regression_model.loc['F-pvalue', 'value']<0.01):\n",
    "        f_prob = '(**)'\n",
    "    elif(regression_model.loc['F-pvalue', 'value']<0.05):\n",
    "        f_prob = '(*)'\n",
    "        \n",
    "    \n",
    "    plot_ci = np.round(regression_model.loc['CI', 'value'],2)\n",
    "    \n",
    "    plt.text(report_pos[0], report_pos[1],\n",
    "             r'$ R^2 = $' + str(np.round(regression_model.loc['R-squared', 'value'],2))+ '\\n$CI = $' + str(plot_ci) + '\\n$F^2 = $' + str(np.round(regression_model.loc['F-squared', 'value'],2)) + ' ' + '\\n$F = $' + str(np.round(regression_model.loc['F', 'value'],2)) + '\\n$P (F) = $' + f_prob + '\\n$n = $' + n,\n",
    "                             size= 12, rotation=0.,\n",
    "                             ha=\"right\", va=\"center\", color = 'black',\n",
    "                             bbox=dict(boxstyle=\"round\",\n",
    "                                       ec='#F6F6F6',\n",
    "                                        fc='#F6F6F6',\n",
    "                                       )\n",
    "                             )\n",
    "\n",
    "    plt.xticks(fontsize=10)\n",
    "    plt.yticks(fontsize=10)\n",
    "    \n",
    "    plt.xlabel('Estimate', fontsize=12)\n",
    "    plt.ylabel('Features', fontsize=12)\n",
    "    plt.locator_params(axis='x', nbins=4)\n",
    "\n",
    "\n",
    "def adj_r2_score_and_r2_score(clf, X, y):\n",
    "    n = X.shape[0]  # Number of observations\n",
    "    p = X.shape[1]  # Number of features\n",
    "    r_squared = r2_score(y, clf.predict(X))\n",
    "    return [1 - (1 - r_squared) * ((n - 1) / (n - p - 1)), r_squared]\n",
    "\n",
    "\n",
    "def mse(clf, X, y):\n",
    "    return mean_squared_error(y, clf.predict(X))\n",
    "\n",
    "def rmse(clf, X, y):\n",
    "    mse = mean_squared_error(y, clf.predict(X))\n",
    "    return math.sqrt(mse)    \n",
    "\n",
    "def coef_se(clf, X, y):\n",
    "    n = X.shape[0]\n",
    "    X1 = np.hstack((np.ones((n, 1)), np.matrix(X)))\n",
    "    se_matrix = scipy.linalg.sqrtm(\n",
    "        metrics.mean_squared_error(y, clf.predict(X)) *\n",
    "        np.linalg.inv(X1.T * X1)\n",
    "    )\n",
    "    return np.diagonal(se_matrix)\n",
    "\n",
    "def coef_tval(clf, X, y):\n",
    "    a = np.array(clf.intercept_ / coef_se(clf, X, y)[0])\n",
    "    b = np.array(clf.coef_ / coef_se(clf, X, y)[1:])\n",
    "    return np.append(a, b)\n",
    "\n",
    "def coef_tval_SVR_tree(clf, X, y):\n",
    "    a = np.array(clf.intercept_ / coef_se(clf, X, y)[0])\n",
    "    b = np.array(clf._get_coef() / coef_se(clf, X, y)[1:])\n",
    "    return np.append(a, b)\n",
    "\n",
    "def coef_pval(clf, X, y):\n",
    "\n",
    "    n = X.shape[0]\n",
    "    t = coef_tval(clf, X, y)\n",
    "    p = 2 * (1 - scipy.stats.t.cdf(abs(t), n - 1))\n",
    "    return p\n",
    "\n",
    "def coef_pval_SVR_tree(clf, X, y):\n",
    "\n",
    "    n = X.shape[0]\n",
    "    t = coef_tval_SVR_tree(clf, X, y)\n",
    "    p = 2 * (1 - scipy.stats.t.cdf(abs(t), n - 1))\n",
    "    return p\n",
    "\n",
    "def residuals(clf, X, y, r_type='standardized'):\n",
    "\n",
    "    # Make sure value of parameter 'r_type' is one we recognize\n",
    "    assert r_type in ('raw', 'standardized', 'studentized'), (\n",
    "        \"Invalid option for 'r_type': {0}\".format(r_type))\n",
    "    y_true = y.view(dtype='float')\n",
    "    # Use classifier to make predictions\n",
    "    y_pred = clf.predict(X)\n",
    "    # Make sure dimensions agree (Numpy still allows subtraction if they don't)\n",
    "    assert y_true.shape == y_pred.shape, (\n",
    "        \"Dimensions of y_true {0} do not match y_pred {1}\".format(y_true.shape,\n",
    "                                                                  y_pred.shape))\n",
    "    # Get raw residuals, or standardized or standardized residuals\n",
    "    resids = y_pred - y_true\n",
    "    if r_type == 'standardized':\n",
    "        resids = resids / np.std(resids)\n",
    "    elif r_type == 'studentized':\n",
    "        # Prepare a blank array to hold studentized residuals\n",
    "        studentized_resids = np.zeros(y_true.shape[0], dtype='float')\n",
    "        # Calcluate hat matrix of X values so you can get leverage scores\n",
    "        hat_matrix = np.dot(\n",
    "            np.dot(X, np.linalg.inv(np.dot(np.transpose(X), X))),\n",
    "            np.transpose(X))\n",
    "        # For each point, calculate studentized residuals w/ leave-one-out MSE\n",
    "        for i in range(y_true.shape[0]):\n",
    "            # Make a mask so you can calculate leave-one-out MSE\n",
    "            mask = np.ones(y_true.shape[0], dtype='bool')\n",
    "            mask[i] = 0\n",
    "            loo_mse = np.average(resids[mask] ** 2, axis=0)  # Leave-one-out MSE\n",
    "            # Calculate studentized residuals\n",
    "            studentized_resids[i] = resids[i] / np.sqrt(\n",
    "                loo_mse * (1 - hat_matrix[i, i]))\n",
    "        resids = studentized_resids\n",
    "    return resids\n",
    "\n",
    "\n",
    "def f_squared(clf, X, y):\n",
    "\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1]\n",
    "    r_squared = metrics.r2_score(y, clf.predict(X))\n",
    "    return r_squared  / (1 - r_squared)\n",
    "\n",
    "def f_stat(clf, X, y):\n",
    "    \"\"\"Calculate summary F-statistic for beta coefficients.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The F-statistic value.\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1]\n",
    "    r_squared = metrics.r2_score(y, clf.predict(X))\n",
    "    return (r_squared / p) / ((1 - r_squared) / (n - p - 1))\n",
    "\n",
    "\n",
    "def f_stat_pvalue(clf, X, y):\n",
    "    \"\"\"Calculate summary F-statistic p value for beta coefficients.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The F-statistic p value.\n",
    "    \"\"\"\n",
    "    n = X.shape[0] # Esto se extrae par los grados de libertad del numeador y el denomindor (no. predictores, no. sujetos - no. predictores-1)\n",
    "    p = X.shape[1]\n",
    "    r_squared = metrics.r2_score(y, clf.predict(X))\n",
    "    \n",
    "    return np.round(scipy.stats.f.sf(f_stat(clf, X, y), n, (n - p - 1)), 15)\n",
    "\n",
    "def compute_f_statistics(clf, X, y):\n",
    "    return [f_stat(clf, X, y), f_stat_pvalue(clf, X, y)]\n",
    "\n",
    "\n",
    "\n",
    "def boostrapping(X_func, case1A_func, case1A_func_for_strat, lista_best_func, model_ = SVR(kernel='rbf', degree=4)):\n",
    "    print(model_)\n",
    "    \n",
    "    coef_array_func = np.zeros([len(lista_best_func)+1, 1000])\n",
    "    coef_t_value_func = np.zeros([len(lista_best_func)+1, 1000])\n",
    "    coef_p_value_func = np.zeros([len(lista_best_func)+1, 1000])\n",
    "\n",
    "    r2_list_func =[]\n",
    "    f2_list_func =[]\n",
    "    f_list_func =[]\n",
    "    f_p_value_list_func =[]\n",
    "    for iter in tqdm(range(0,1000), total=len(range(0, 1000)),leave=True, mininterval=1, ascii=True,\n",
    "                            colour='green', desc='Training model'):\n",
    "        # Stratified split\n",
    "        seed = np.random.randint(100, 200)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_func, case1A_func, stratify=case1A_func_for_strat,test_size=0.30, random_state=seed)\n",
    "\n",
    "        model_func = model_\n",
    "\n",
    "        model_func.fit(X_train, y_train)\n",
    "\n",
    "        coef_array_func[0,iter] = np.abs(model_func.intercept_)\n",
    "        coef_array_func[1::,iter] = np.abs(model_func._get_coef())\n",
    "\n",
    "\n",
    "        coef_t_value_func[:,iter] = np.round(coef_tval_SVR_tree(model_func, X_test, y_test), 30)\n",
    "        coef_p_value_func[:,iter] = np.round(coef_pval_SVR_tree(model_func, X_test, y_test), 30)\n",
    "\n",
    "\n",
    "        f2_list_func.append(f_squared(model_func, X_test, y_test))\n",
    "        f_list_func.append(f_stat(model_func, X_test, y_test))\n",
    "        f_p_value_list_func.append(f_stat_pvalue(model_func, X_test, y_test))\n",
    "        r2_list_func.append(r2_score(y_test, model_func.predict(X_test)))\n",
    "\n",
    "\n",
    "    r2_list_array = np.array(r2_list_func)\n",
    "    # finding the 1st quartile\n",
    "    q1 = np.quantile(r2_list_array, 0.25)\n",
    " \n",
    "    # finding the 3rd quartile\n",
    "    q3 = np.quantile(r2_list_array, 0.75)\n",
    "    med = np.median(r2_list_array)\n",
    "\n",
    "    # finding the iqr region\n",
    "    iqr = q3-q1\n",
    "\n",
    "    # finding upper and lower whiskers\n",
    "    upper_bound = q3+(1.5*iqr)\n",
    "    lower_bound = q1-(1.5*iqr)\n",
    "    #print(iqr, upper_bound, lower_bound)\n",
    "\n",
    "    index_del = []     \n",
    "\n",
    "    for i in range(r2_list_array.shape[0]):\n",
    "        if((r2_list_array[i]<= lower_bound) | (r2_list_array[i] >= upper_bound)):\n",
    "            index_del.append(i)\n",
    "\n",
    "    \n",
    "    \n",
    "    r2_list_func = list(np.delete(r2_list_array,index_del, axis=0 ))\n",
    "\n",
    "    coef_df_func = pd.DataFrame(\n",
    "            index=['_intercept'] + lista_best_func,\n",
    "            columns=['Estimate','t value', 'p value', 'p value mean']\n",
    "        )\n",
    "\n",
    "    coef_array_func  = np.delete(coef_array_func,index_del, axis=1 )\n",
    "    coef_t_value_func = np.delete(coef_t_value_func,index_del, axis=1 )\n",
    "    coef_p_value_func = np.delete(coef_p_value_func,index_del, axis=1 )\n",
    "    \n",
    "    \n",
    "    coef_array_func_mean = np.zeros([len(lista_best_func)+1, 1])\n",
    "    coef_t_value_func_mean = np.zeros([len(lista_best_func)+1, 1])\n",
    "    coef_p_value_func_mean = np.zeros([len(lista_best_func)+1, 1])\n",
    "    coef_p_value_func_fdr = np.zeros([len(lista_best_func)+1, 1])\n",
    "    \n",
    "    coef_array_func_std = np.zeros([len(lista_best_func)+1, 1])\n",
    "\n",
    "    print('shape',coef_array_func.shape, coef_t_value_func.shape, coef_p_value_func.shape, len(index_del))\n",
    "    \n",
    "    for i in range(len(lista_best_func)+1):\n",
    "        coef_array_func_mean[i] = coef_array_func[i,:].mean()\n",
    "        coef_t_value_func_mean[i]= coef_t_value_func[i,:].mean()\n",
    "        coef_p_value_func_mean[i]= coef_p_value_func[i,:].mean()\n",
    "        coef_p_value_func_fdr[i]= fdrcorrection(coef_p_value_func[i,:], alpha=0.05, is_sorted=False )[1].max()\n",
    "        \n",
    "        coef_array_func_std[i] = coef_array_func[i,:].std()\n",
    "        # Se corrige por FDR y se reporta el valor máximo\n",
    "\n",
    "    coef_df_func['Estimate'] = coef_array_func_mean\n",
    "    coef_df_func['t value'] = coef_t_value_func_mean\n",
    "    coef_df_func['p value'] = coef_p_value_func_fdr\n",
    "    coef_df_func['p value mean'] = coef_p_value_func_mean\n",
    "    coef_df_func['Estimate std'] = coef_array_func_std\n",
    "\n",
    "\n",
    "    empty_str = []\n",
    "    for i in range(coef_df_func.shape[0]):\n",
    "        empty_str.append('')\n",
    "\n",
    "    coef_df_func['value'] = empty_str\n",
    "\n",
    "    coef_df_func = coef_df_func.T\n",
    "    coef_df_func['R-squared'] = ['','','','', '', np.mean(r2_list_func)]\n",
    "    coef_df_func['CI'] = ['','','','', '', np.std(r2_list_func)*1.96]\n",
    "    coef_df_func['F-squared'] = ['','','','', '', np.mean(f2_list_func)]\n",
    "    coef_df_func['F'] = ['','','','', '', np.mean(f_list_func)]\n",
    "    coef_df_func['F-pvalue'] = ['','','','', '', fdrcorrection(f_p_value_list_func, alpha=0.05, is_sorted=False )[1].max()]\n",
    "    \n",
    "    #coef_df_func['F-pvalue_fdr'] = ['','','', fdrcorrection(f_p_value_list_func, alpha=0.05, method='indep', is_sorted=False )]\n",
    "    coef_df_func = coef_df_func.T\n",
    "\n",
    "\n",
    "    print(np.mean(r2_list_func),  np.std(r2_list_func)*1.96)\n",
    "    \n",
    "    return [coef_df_func, r2_list_func, f_p_value_list_func, fdrcorrection(f_p_value_list_func, alpha=0.05, is_sorted=False )]\n",
    "\n",
    "   \n",
    "    \n",
    "def SearchBestModel(case_x, case_y, case_x_for_strat):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(case_x, case_y, test_size=.30, stratify=case_x_for_strat, random_state=1)\n",
    "\n",
    "    opt_SVR = BayesSearchCV(\n",
    "            SVR(),\n",
    "            {\n",
    "                #'gamma': ( 0.0001, 0.01, 0.001, 0.1, 1, 10),\n",
    "                'kernel': ['rbf'],\n",
    "                'degree': (3, 4, 5, 6),\n",
    "                #'tol:' : (1e-6, 1e-3, 1e+1),\n",
    "                #'n_estimators': (100, 1000),\n",
    "\n",
    "            },\n",
    "            n_iter=10,\n",
    "            cv=3, random_state=1\n",
    "        )\n",
    "\n",
    "    opt_SVR.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    print('SVR')\n",
    "    print(\"val. score: %s\" % opt_SVR.best_score_)\n",
    "    print(\"test score: %s\" % opt_SVR.score(X_test, y_test))\n",
    "    print(\"best parameters: %s\" % str(opt_SVR.best_params_))\n",
    "    print('---------------------------------------------\\n')\n",
    "    \n",
    "    return opt_SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colors, variables names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat = pd.read_csv('../Data/var_name_color_code.csv', encoding='latin-1', sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = pd.read_excel('../Data/Base.xlsx', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunm = 'diagnosis_specify'\n",
    "cn_col = data_[colunm]\n",
    "\n",
    "data_[colunm] = data_[colunm].apply(lambda x: (x-cn_col.mean())/ cn_col.std())\n",
    "\n",
    "\n",
    "colunm = 'country_class'\n",
    "cn_col = data_[colunm]\n",
    "\n",
    "data_[colunm] = data_[colunm].apply(lambda x: (x-cn_col.mean())/ cn_col.std())\n",
    "\n",
    "colunm = 'Edad_procesada'\n",
    "cn_col = data_[colunm]\n",
    "\n",
    "data_[colunm] = data_[colunm].apply(lambda x: (x-cn_col.mean())/ cn_col.std())\n",
    "\n",
    "\n",
    "colunm = 'years_education'\n",
    "cn_col = data_[colunm]\n",
    "\n",
    "data_[colunm] = data_[colunm].apply(lambda x: (x-cn_col.mean())/ cn_col.std())\n",
    "\n",
    "colunm = 'cognition_general_score'\n",
    "cn_col = data_[colunm]\n",
    "\n",
    "data_[colunm] = data_[colunm].apply(lambda x: (x-cn_col.mean())/ cn_col.std())\n",
    "\n",
    "\n",
    "colunm = 'executive_score'\n",
    "cn_col = data_[colunm]\n",
    "\n",
    "data_[colunm] = data_[colunm].apply(lambda x: (x-cn_col.mean())/ cn_col.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_z_score = data_.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_z_score.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demographics and cognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reduc_1A_zscore = conn_z_score.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_z_score_fer = data_reduc_1A_zscore.drop([              'mini_sea_tom', 'mini_sea_total'], axis =1 )\n",
    "conn_z_score_tom = data_reduc_1A_zscore.drop(['mini_sea_fer',                 'mini_sea_total'], axis =1 )\n",
    "conn_z_score_tot = data_reduc_1A_zscore.drop(['mini_sea_fer', 'mini_sea_tom',                 ], axis =1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_z_score_fer.dropna(inplace=True)\n",
    "conn_z_score_tom.dropna(inplace=True)  \n",
    "conn_z_score_tot.dropna(inplace=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(998, 8) (998, 8) (998, 8)\n"
     ]
    }
   ],
   "source": [
    "print(conn_z_score_fer.shape,\n",
    "conn_z_score_tom.shape,  \n",
    "conn_z_score_tot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## y data\n",
    "y_1A_fer = conn_z_score_fer['mini_sea_fer']\n",
    "y_1A_tom = conn_z_score_tom['mini_sea_tom']\n",
    "y_1A_tot = conn_z_score_tot['mini_sea_total']\n",
    "\n",
    "\n",
    "## x data\n",
    "X_1A_fer = conn_z_score_fer.drop(['mini_sea_fer'], axis =1 )\n",
    "X_1A_tom = conn_z_score_tom.drop(['mini_sea_tom'], axis =1 )\n",
    "X_1A_tot = conn_z_score_tot.drop(['mini_sea_total'], axis =1 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boostrapping and Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR\n",
      "val. score: 0.3342902558222461\n",
      "test score: 0.32021944179817374\n",
      "best parameters: OrderedDict([('degree', 5), ('kernel', 'rbf')])\n",
      "---------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_1A_fer_for_strat =  y_1A_fer.copy()\n",
    "median = y_1A_fer_for_strat.median()\n",
    "y_1A_fer_for_strat.loc[y_1A_fer_for_strat<median]= 0\n",
    "y_1A_fer_for_strat.loc[y_1A_fer_for_strat>=median]=1 \n",
    "\n",
    "\n",
    "opt_SVR_fer = SearchBestModel(X_1A_fer, y_1A_fer, y_1A_fer_for_strat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR\n",
      "val. score: 0.3520572199003\n",
      "test score: 0.26295314528654523\n",
      "best parameters: OrderedDict([('degree', 5), ('kernel', 'rbf')])\n",
      "---------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_1A_tom_for_strat =  y_1A_tom.copy()\n",
    "median = y_1A_tom_for_strat.median()\n",
    "y_1A_tom_for_strat.loc[y_1A_tom_for_strat<median]= 0\n",
    "y_1A_tom_for_strat.loc[y_1A_tom_for_strat>=median]=1 \n",
    "\n",
    "\n",
    "opt_SVR_tom = SearchBestModel(X_1A_tom, y_1A_tom, y_1A_tom_for_strat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR\n",
      "val. score: 0.39521707611199836\n",
      "test score: 0.4733987206514443\n",
      "best parameters: OrderedDict([('degree', 5), ('kernel', 'rbf')])\n",
      "---------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_1A_tot_for_strat =  y_1A_tot.copy()\n",
    "median = y_1A_tot_for_strat.median()\n",
    "y_1A_tot_for_strat.loc[y_1A_tot_for_strat<median]= 0\n",
    "y_1A_tot_for_strat.loc[y_1A_tot_for_strat>=median]=1 \n",
    "\n",
    "opt_SVR_tot = SearchBestModel(X_1A_tot, y_1A_tot, y_1A_tot_for_strat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boostrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR(degree=4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ae1fc3a4804cb79449b0e848c5697a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training model:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (8, 1000) (8, 1000) (8, 1000) 0\n",
      "0.34586585977296963 0.07434941211475332\n",
      "SVR(degree=4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d306a4d89bc24927a05899e9e29ff3a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training model:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (8, 1000) (8, 1000) (8, 1000) 0\n",
      "0.3399315677373424 0.08521541918695502\n",
      "SVR(degree=4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaefd441361041de94fc8a5c535a2444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training model:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (8, 982) (8, 982) (8, 982) 18\n",
      "0.4419682105811034 0.0656704517800694\n"
     ]
    }
   ],
   "source": [
    "coef_SVR_fer = boostrapping(X_1A_fer, y_1A_fer, y_1A_fer_for_strat, list(X_1A_fer.columns))\n",
    "coef_SVR_tom = boostrapping(X_1A_tom, y_1A_tom, y_1A_tom_for_strat, list(X_1A_tom.columns))\n",
    "coef_SVR_tot = boostrapping(X_1A_tot, y_1A_tot, y_1A_tot_for_strat, list(X_1A_tot.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coef_SVR_fer[0].to_excel('Results/Fig_2_panel_1/fer.xlsx')\n",
    "#coef_SVR_tom[0].to_excel('Results/Fig_2_panel_1/tom.xlsx')\n",
    "#coef_SVR_tot[0].to_excel('Results/Fig_2_panel_1/tot.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
