{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d54dfb1",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f44fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import plot_importance\n",
    "import plotly.graph_objects as go\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, f1_score, accuracy_score, recall_score, precision_score, confusion_matrix, mean_squared_error\n",
    "import seaborn as sns\n",
    "from statannot import add_stat_annotation\n",
    "from sklearn.linear_model import Lasso, MultiTaskLasso, Ridge, ElasticNet\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import mutual_info_regression, f_regression\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import time\n",
    "import scipy\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "\n",
    "from statsmodels.stats import multitest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7560232",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f28081",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROIs\n",
    "SN = [\"31. Cingulum_Ant_L'\",\"32. Cingulum_Ant_R'\", \"29. Insula_L'\",\"30. Insula_R'\"]\n",
    "DMN = [\"23. Frontal_Sup_Medial_L'\", \"24. Frontal_Sup_Medial_R'\", \"35. Cingulum_Post_L'\",\n",
    "\"36. Cingulum_Post_R'\"]\n",
    "EN=[\"7. Frontal_Mid_L'\", \"8. Frontal_Mid_R'\",\"61. Parietal_Inf_L'\",\n",
    "\"62. Parietal_Inf_R'\"]\n",
    "VN= [\"49. Occipital_Sup_L'\", \"50. Occipital_Sup_R'\", \"51. Occipital_Mid_L'\", \"52. Occipital_Mid_R'\",\n",
    "     \"53. Occipital_Inf_L'\", \"54. Occipital_Inf_R'\"]\n",
    "MN=[\"1. Precentral_L'\",\"2. Precentral_R'\"]\n",
    "\n",
    "fun_cols = ['id', 'Promedio_traslacion', 'Promedio_rotacion', 'DMN','EN', 'MN', 'SN', 'VN']\n",
    "best = SN + DMN + EN + VN + MN +  ['Promedio_traslacion', 'Promedio_rotacion', 'DMN','EN', 'MN', 'SN', 'VN']\n",
    "\n",
    "\n",
    "\n",
    "def get_color(var, X_cat_, color_dict_):\n",
    "\n",
    "    X_factors = list(X_cat_.factors)\n",
    "    X_name = list(X_cat_.newname)\n",
    "\n",
    "    index_code = X_name.index(var)\n",
    "    cat = X_factors[index_code]\n",
    "\n",
    "    return color_dict_[cat]\n",
    "\n",
    "\n",
    "def get_bar_colors(data_, X_cat_):\n",
    "    color_dict = {}\n",
    "    color_dict['FP'] = '#FAF85F'\n",
    "    color_dict['HF'] = '#cc8963' #b55d60\n",
    "    color_dict['FF1'] = '#FF9E0D'\n",
    "    color_dict['CF'] = '#b55d60' #cc8963\n",
    "    color_dict['FF'] = '#5975a4'\n",
    "    color_dict['DF'] = '#5f9e6e'\n",
    "    color_dict['FlairFL'] = '#DAEB07'\n",
    "    color_dict['FlairFR'] = '#EB9700'\n",
    "    color_dict['FlairF'] = '#FFD400'\n",
    "    color_dict['GMF'] = '#757575'\n",
    "    color_dict['WMF'] = '#DADEE0'\n",
    "\n",
    "    X_factors = list(X_cat_.factors)\n",
    "    X_name = list(X_cat_.name)\n",
    "\n",
    "    bar_color_total = []\n",
    "    for i in list(data_.Features):\n",
    "        if(i == 'Country'):\n",
    "            bar_color_total.append(color_dict['Country'])\n",
    "            continue\n",
    "        index_code = X_name.index(i)\n",
    "        cat = X_factors[index_code]\n",
    "        bar_color_total.append(color_dict[cat])\n",
    "    return bar_color_total\n",
    "\n",
    "\n",
    "\n",
    "def plot_estimate_value_v1(regression_model, X_cat_ = [], title = '',  xlim =[0, 2] ,fig_size = (8,12), size = 12, pvalue_type = 'False', plot_ci = '', report_pos = [50, 4], n = 10):\n",
    "\n",
    "    df = regression_model\n",
    "    df.index.name = 'Features'\n",
    "    df = df.iloc[1:-5, 0:-1]\n",
    "\n",
    "    for i in range(3):\n",
    "            #print(i, X_RAW_edu_level[X_RAW_edu_level.columns[i]].dtype)\n",
    "        df[df.columns[i]] = np.abs(pd.to_numeric(df[df.columns[i]],errors = 'coerce'))\n",
    "\n",
    "    df = df.reset_index()\n",
    "    data = df.sort_values('Estimate', ascending=False)\n",
    "\n",
    "    \n",
    "    if(len(X_cat_)>0):\n",
    "        \n",
    "        bar_color = get_bar_colors(data, X_cat_)\n",
    "        \n",
    "        plt.title(title)\n",
    "        sns.barplot(x=\"Estimate\", y=\"Features\", data = data, xerr=data['Estimate std'], palette =bar_color)\n",
    "        plt.xlim(xlim)\n",
    "    else:\n",
    "        plt.title(title)\n",
    "        sns.barplot(x=\"Estimate\", y=\"Features\", data = data, color = 'darkblue')\n",
    "        plt.xlim(xlim)\n",
    "\n",
    "\n",
    "    y_step=0  \n",
    "    for i in range(df.shape[0]):\n",
    "        if(np.round(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step],3)<=0.01):\n",
    "            color = 'green'\n",
    "        elif(np.round(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step],3)<=0.05):\n",
    "            color = 'gray'\n",
    "        else:\n",
    "            color = 'red'        \n",
    "        \n",
    "        if(pvalue_type == 'color'):\n",
    "                plt.text(df.sort_values('Estimate', ascending=False)['Estimate'].iloc[y_step]-0.005, y_step, \n",
    "                                 '' + str(np.round(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step],2)),\n",
    "                                 size= size, rotation=0.,\n",
    "                                 ha=\"left\", va=\"center\", color = 'white',\n",
    "                                 bbox=dict(boxstyle=\"round\",\n",
    "                                           ec=color,\n",
    "                                            fc=color,\n",
    "                                           )\n",
    "                                 )\n",
    "                y_step+=1\n",
    "\n",
    "        elif(pvalue_type == 'value'):\n",
    "                plt.text(df.sort_values('Estimate', ascending=False)['Estimate'].iloc[y_step]+0.005, y_step, \n",
    "                                 '(' + str(np.round(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step],8))+')',\n",
    "                                 size= size, rotation=0.,\n",
    "                                 ha=\"left\", va=\"center\", color = 'black',\n",
    "\n",
    "                                 )\n",
    "                y_step+=1\n",
    "        else:\n",
    "            \n",
    "            if(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step]<0.01):\n",
    "                \n",
    "                    plt.text(df.sort_values('Estimate', ascending=False)['Estimate'].iloc[y_step]+0.005, y_step, \n",
    "                                     '**',\n",
    "                                     size= size, rotation=0.,\n",
    "                                     ha=\"left\", va=\"center\", color = 'black',\n",
    "\n",
    "                                     )\n",
    "            elif(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step]>= 0.01 and df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step]<0.05):\n",
    "                  \n",
    "                    plt.text(df.sort_values('Estimate', ascending=False)['Estimate'].iloc[y_step]+0.005, y_step, \n",
    "                                     '*',\n",
    "                                     size= size, rotation=0.,\n",
    "                                     ha=\"left\", va=\"center\", color = 'black',\n",
    "\n",
    "                                     )  \n",
    "            else:\n",
    "                    plt.text(df.sort_values('Estimate', ascending=False)['Estimate'].iloc[y_step]+0.005, y_step, \n",
    "                                     ' ',\n",
    "                                     size= size, rotation=0.,\n",
    "                                     ha=\"left\", va=\"center\", color = 'black',\n",
    "\n",
    "                                     )    \n",
    "\n",
    "            y_step+=1\n",
    "            \n",
    "         \n",
    "    text_diff =xlim[1]\n",
    "    #coef_SVR_tot.loc['R-squared', 'value']\n",
    "    f_prob = '(ns)'\n",
    "    if(regression_model.loc['F-pvalue', 'value']<0.01):\n",
    "        f_prob = '(**)'\n",
    "    elif(regression_model.loc['F-pvalue', 'value']<0.05):\n",
    "        f_prob = '(*)'\n",
    "        \n",
    "    \n",
    "    plot_ci = np.round(regression_model.loc['CI', 'value'],2)\n",
    "    \n",
    "    plt.text(report_pos[0], report_pos[1],\n",
    "             r'$ R^2 = $' + str(np.round(regression_model.loc['R-squared', 'value'],2))+ '\\n$CI = $' + str(plot_ci) + '\\n$F^2 = $' + str(np.round(regression_model.loc['F-squared', 'value'],2)) + ' ' + '\\n$F = $' + str(np.round(regression_model.loc['F', 'value'],2)) + '\\n$P (F) = $' + f_prob + '\\n$n = $' + n,\n",
    "                             size= 12, rotation=0.,\n",
    "                             ha=\"right\", va=\"center\", color = 'black',\n",
    "                             bbox=dict(boxstyle=\"round\",\n",
    "                                       ec='#F6F6F6',\n",
    "                                        fc='#F6F6F6',\n",
    "                                       )\n",
    "                             )\n",
    "\n",
    "    plt.xticks(fontsize=10)\n",
    "    plt.yticks(fontsize=10)\n",
    "    \n",
    "    plt.xlabel('Estimate', fontsize=12)\n",
    "    plt.ylabel('Features', fontsize=12)\n",
    "    plt.locator_params(axis='x', nbins=4)\n",
    "\n",
    "\n",
    "\n",
    "def adj_r2_score_and_r2_score(clf, X, y):\n",
    "    n = X.shape[0]  # Number of observations\n",
    "    p = X.shape[1]  # Number of features\n",
    "    r_squared = r2_score(y, clf.predict(X))\n",
    "    return [1 - (1 - r_squared) * ((n - 1) / (n - p - 1)), r_squared]\n",
    "\n",
    "\n",
    "def mse(clf, X, y):\n",
    "    return mean_squared_error(y, clf.predict(X))\n",
    "\n",
    "def rmse(clf, X, y):\n",
    "    mse = mean_squared_error(y, clf.predict(X))\n",
    "    return math.sqrt(mse)    \n",
    "\n",
    "def coef_se(clf, X, y):\n",
    "    n = X.shape[0]\n",
    "    X1 = np.hstack((np.ones((n, 1)), np.matrix(X)))\n",
    "    se_matrix = scipy.linalg.sqrtm(\n",
    "        metrics.mean_squared_error(y, clf.predict(X)) *\n",
    "        np.linalg.inv(X1.T * X1)\n",
    "    )\n",
    "    return np.diagonal(se_matrix)\n",
    "\n",
    "def coef_tval(clf, X, y):\n",
    "    a = np.array(clf.intercept_ / coef_se(clf, X, y)[0])\n",
    "    b = np.array(clf.coef_ / coef_se(clf, X, y)[1:])\n",
    "    return np.append(a, b)\n",
    "\n",
    "def coef_tval_SVR_tree(clf, X, y):\n",
    "    a = np.array(clf.intercept_ / coef_se(clf, X, y)[0])\n",
    "    b = np.array(clf._get_coef() / coef_se(clf, X, y)[1:])\n",
    "    return np.append(a, b)\n",
    "\n",
    "def coef_pval(clf, X, y):\n",
    "\n",
    "    n = X.shape[0]\n",
    "    t = coef_tval(clf, X, y)\n",
    "    p = 2 * (1 - scipy.stats.t.cdf(abs(t), n - 1))\n",
    "    return p\n",
    "\n",
    "def coef_pval_SVR_tree(clf, X, y):\n",
    "\n",
    "    n = X.shape[0]\n",
    "    t = coef_tval_SVR_tree(clf, X, y)\n",
    "    p = 2 * (1 - scipy.stats.t.cdf(abs(t), n - 1))\n",
    "    return p\n",
    "\n",
    "def residuals(clf, X, y, r_type='standardized'):\n",
    "\n",
    "    # Make sure value of parameter 'r_type' is one we recognize\n",
    "    assert r_type in ('raw', 'standardized', 'studentized'), (\n",
    "        \"Invalid option for 'r_type': {0}\".format(r_type))\n",
    "    y_true = y.view(dtype='float')\n",
    "    # Use classifier to make predictions\n",
    "    y_pred = clf.predict(X)\n",
    "    # Make sure dimensions agree (Numpy still allows subtraction if they don't)\n",
    "    assert y_true.shape == y_pred.shape, (\n",
    "        \"Dimensions of y_true {0} do not match y_pred {1}\".format(y_true.shape,\n",
    "                                                                  y_pred.shape))\n",
    "    # Get raw residuals, or standardized or standardized residuals\n",
    "    resids = y_pred - y_true\n",
    "    if r_type == 'standardized':\n",
    "        resids = resids / np.std(resids)\n",
    "    elif r_type == 'studentized':\n",
    "        # Prepare a blank array to hold studentized residuals\n",
    "        studentized_resids = np.zeros(y_true.shape[0], dtype='float')\n",
    "        # Calcluate hat matrix of X values so you can get leverage scores\n",
    "        hat_matrix = np.dot(\n",
    "            np.dot(X, np.linalg.inv(np.dot(np.transpose(X), X))),\n",
    "            np.transpose(X))\n",
    "        # For each point, calculate studentized residuals w/ leave-one-out MSE\n",
    "        for i in range(y_true.shape[0]):\n",
    "            # Make a mask so you can calculate leave-one-out MSE\n",
    "            mask = np.ones(y_true.shape[0], dtype='bool')\n",
    "            mask[i] = 0\n",
    "            loo_mse = np.average(resids[mask] ** 2, axis=0)  # Leave-one-out MSE\n",
    "            # Calculate studentized residuals\n",
    "            studentized_resids[i] = resids[i] / np.sqrt(\n",
    "                loo_mse * (1 - hat_matrix[i, i]))\n",
    "        resids = studentized_resids\n",
    "    return resids\n",
    "\n",
    "\n",
    "def f_squared(clf, X, y):\n",
    "\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1]\n",
    "    r_squared = metrics.r2_score(y, clf.predict(X))\n",
    "    return r_squared  / (1 - r_squared)\n",
    "\n",
    "def f_stat(clf, X, y):\n",
    "    \"\"\"Calculate summary F-statistic for beta coefficients.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The F-statistic value.\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1]\n",
    "    r_squared = metrics.r2_score(y, clf.predict(X))\n",
    "    return (r_squared / p) / ((1 - r_squared) / (n - p - 1))\n",
    "\n",
    "\n",
    "def f_stat_pvalue(clf, X, y):\n",
    "    \"\"\"Calculate summary F-statistic p value for beta coefficients.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The F-statistic p value.\n",
    "    \"\"\"\n",
    "    n = X.shape[0] # Esto se extrae par los grados de libertad del numeador y el denomindor (no. predictores, no. sujetos - no. predictores-1)\n",
    "    p = X.shape[1]\n",
    "    r_squared = metrics.r2_score(y, clf.predict(X))\n",
    "    \n",
    "    return np.round(scipy.stats.f.sf(f_stat(clf, X, y), n, (n - p - 1)), 15)\n",
    "\n",
    "def compute_f_statistics(clf, X, y):\n",
    "    return [f_stat(clf, X, y), f_stat_pvalue(clf, X, y)]\n",
    "\n",
    "\n",
    "\n",
    "def boostrapping(X_func, case1A_func, case1A_func_for_strat, lista_best_func, model_ = SVR(kernel='rbf', degree=4)):\n",
    "    print(model_)\n",
    "    \n",
    "    coef_array_func = np.zeros([len(lista_best_func)+1, 1000])\n",
    "    coef_t_value_func = np.zeros([len(lista_best_func)+1, 1000])\n",
    "    coef_p_value_func = np.zeros([len(lista_best_func)+1, 1000])\n",
    "\n",
    "    r2_list_func =[]\n",
    "    f2_list_func =[]\n",
    "    f_list_func =[]\n",
    "    f_p_value_list_func =[]\n",
    "    for iter in tqdm(range(0,1000), total=len(range(0, 1000)),leave=True, mininterval=1, ascii=True,\n",
    "                            desc='Training model'):\n",
    "        # Stratified split\n",
    "        seed = np.random.randint(100, 200)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_func, case1A_func, stratify=case1A_func_for_strat,test_size=0.30, random_state=seed)\n",
    "\n",
    "        model_func = model_\n",
    "\n",
    "        model_func.fit(X_train, y_train)\n",
    "\n",
    "        coef_array_func[0,iter] = np.abs(model_func.intercept_)\n",
    "        coef_array_func[1::,iter] = np.abs(model_func._get_coef())\n",
    "\n",
    "\n",
    "        coef_t_value_func[:,iter] = np.round(coef_tval_SVR_tree(model_func, X_test, y_test), 30)\n",
    "        coef_p_value_func[:,iter] = np.round(coef_pval_SVR_tree(model_func, X_test, y_test), 30)\n",
    "\n",
    "\n",
    "        f2_list_func.append(f_squared(model_func, X_test, y_test))\n",
    "        f_list_func.append(f_stat(model_func, X_test, y_test))\n",
    "        f_p_value_list_func.append(f_stat_pvalue(model_func, X_test, y_test))\n",
    "        r2_list_func.append(r2_score(y_test, model_func.predict(X_test)))\n",
    "\n",
    "\n",
    "    r2_list_array = np.array(r2_list_func)\n",
    "    # finding the 1st quartile\n",
    "    q1 = np.quantile(r2_list_array, 0.25)\n",
    " \n",
    "    # finding the 3rd quartile\n",
    "    q3 = np.quantile(r2_list_array, 0.75)\n",
    "    med = np.median(r2_list_array)\n",
    "\n",
    "    # finding the iqr region\n",
    "    iqr = q3-q1\n",
    "\n",
    "    # finding upper and lower whiskers\n",
    "    upper_bound = q3+(1.5*iqr)\n",
    "    lower_bound = q1-(1.5*iqr)\n",
    "    #print(iqr, upper_bound, lower_bound)\n",
    "\n",
    "    index_del = []     \n",
    "\n",
    "    for i in range(r2_list_array.shape[0]):\n",
    "        if((r2_list_array[i]<= lower_bound) | (r2_list_array[i] >= upper_bound)):\n",
    "            index_del.append(i)\n",
    "\n",
    "    \n",
    "    \n",
    "    r2_list_func = list(np.delete(r2_list_array,index_del, axis=0 ))\n",
    "\n",
    "    coef_df_func = pd.DataFrame(\n",
    "            index=['_intercept'] + lista_best_func,\n",
    "            columns=['Estimate','t value', 'p value', 'p value mean']\n",
    "        )\n",
    "\n",
    "    coef_array_func  = np.delete(coef_array_func,index_del, axis=1 )\n",
    "    coef_t_value_func = np.delete(coef_t_value_func,index_del, axis=1 )\n",
    "    coef_p_value_func = np.delete(coef_p_value_func,index_del, axis=1 )\n",
    "    \n",
    "    \n",
    "    coef_array_func_mean = np.zeros([len(lista_best_func)+1, 1])\n",
    "    coef_t_value_func_mean = np.zeros([len(lista_best_func)+1, 1])\n",
    "    coef_p_value_func_mean = np.zeros([len(lista_best_func)+1, 1])\n",
    "    coef_p_value_func_fdr = np.zeros([len(lista_best_func)+1, 1])\n",
    "    \n",
    "    coef_array_func_std = np.zeros([len(lista_best_func)+1, 1])\n",
    "\n",
    "    print('shape',coef_array_func.shape, coef_t_value_func.shape, coef_p_value_func.shape, len(index_del))\n",
    "    \n",
    "    for i in range(len(lista_best_func)+1):\n",
    "        coef_array_func_mean[i] = coef_array_func[i,:].mean()\n",
    "        coef_t_value_func_mean[i]= coef_t_value_func[i,:].mean()\n",
    "        coef_p_value_func_mean[i]= coef_p_value_func[i,:].mean()\n",
    "        coef_p_value_func_fdr[i]= fdrcorrection(coef_p_value_func[i,:], alpha=0.05, is_sorted=False )[1].max()\n",
    "        \n",
    "        coef_array_func_std[i] = coef_array_func[i,:].std()\n",
    "        # Se corrige por FDR y se reporta el valor máximo\n",
    "\n",
    "    coef_df_func['Estimate'] = coef_array_func_mean\n",
    "    coef_df_func['t value'] = coef_t_value_func_mean\n",
    "    coef_df_func['p value'] = coef_p_value_func_fdr\n",
    "    coef_df_func['p value mean'] = coef_p_value_func_mean\n",
    "    coef_df_func['Estimate std'] = coef_array_func_std\n",
    "\n",
    "\n",
    "    empty_str = []\n",
    "    for i in range(coef_df_func.shape[0]):\n",
    "        empty_str.append('')\n",
    "\n",
    "    coef_df_func['value'] = empty_str\n",
    "\n",
    "    coef_df_func = coef_df_func.T\n",
    "    coef_df_func['R-squared'] = ['','','','', '', np.mean(r2_list_func)]\n",
    "    coef_df_func['CI'] = ['','','','', '', np.std(r2_list_func)*1.96]\n",
    "    coef_df_func['F-squared'] = ['','','','', '', np.mean(f2_list_func)]\n",
    "    coef_df_func['F'] = ['','','','', '', np.mean(f_list_func)]\n",
    "    coef_df_func['F-pvalue'] = ['','','','', '', fdrcorrection(f_p_value_list_func, alpha=0.05, is_sorted=False )[1].max()]\n",
    "    \n",
    "    #coef_df_func['F-pvalue_fdr'] = ['','','', fdrcorrection(f_p_value_list_func, alpha=0.05, method='indep', is_sorted=False )]\n",
    "    coef_df_func = coef_df_func.T\n",
    "\n",
    "\n",
    "    print(np.mean(r2_list_func),  np.std(r2_list_func)*1.96)\n",
    "    \n",
    "    return [coef_df_func, r2_list_func, f_p_value_list_func, fdrcorrection(f_p_value_list_func, alpha=0.05, is_sorted=False )]\n",
    "\n",
    "\n",
    "def plot_estimate_value(regression_model, X_cat_ = [], title = '',  xlim =[0, 2] ,fig_size = (8,12), size = 12, pvalue_type = 'False', plot_ci = ''):\n",
    "\n",
    "    df = regression_model\n",
    "    df.index.name = 'Features'\n",
    "    df = df.iloc[1:-5, 0:-1]\n",
    "\n",
    "    for i in range(3):\n",
    "            #print(i, X_RAW_edu_level[X_RAW_edu_level.columns[i]].dtype)\n",
    "        df[df.columns[i]] = np.abs(pd.to_numeric(df[df.columns[i]],errors = 'coerce'))\n",
    "\n",
    "    df = df.reset_index()\n",
    "    data = df.sort_values('Estimate', ascending=False)\n",
    "\n",
    "    \n",
    "    if(len(X_cat_)>0):\n",
    "        \n",
    "        bar_color = get_bar_colors(data, X_cat_)\n",
    "        \n",
    "        plt.title(title)\n",
    "        sns.barplot(x=\"Estimate\", y=\"Features\", data = data, xerr=data['Estimate std'], palette =bar_color)\n",
    "        plt.xlim(xlim)\n",
    "    else:\n",
    "        plt.title(title)\n",
    "        sns.barplot(x=\"Estimate\", y=\"Features\", data = data, color = 'darkblue')\n",
    "        plt.xlim(xlim)\n",
    "\n",
    "\n",
    "    y_step=0  \n",
    "    for i in range(df.shape[0]):\n",
    "        if(np.round(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step],3)<=0.01):\n",
    "            color = 'green'\n",
    "        elif(np.round(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step],3)<=0.05):\n",
    "            color = 'gray'\n",
    "        else:\n",
    "            color = 'red'        \n",
    "        \n",
    "        if(pvalue_type == 'color'):\n",
    "                plt.text(df.sort_values('Estimate', ascending=False)['Estimate'].iloc[y_step]-0.005, y_step, \n",
    "                                 '' + str(np.round(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step],2)),\n",
    "                                 size= size, rotation=0.,\n",
    "                                 ha=\"left\", va=\"center\", color = 'white',\n",
    "                                 bbox=dict(boxstyle=\"round\",\n",
    "                                           ec=color,\n",
    "                                            fc=color,\n",
    "                                           )\n",
    "                                 )\n",
    "                y_step+=1\n",
    "\n",
    "        elif(pvalue_type == 'value'):\n",
    "                plt.text(df.sort_values('Estimate', ascending=False)['Estimate'].iloc[y_step]+0.005, y_step, \n",
    "                                 '(' + str(np.round(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step],8))+')',\n",
    "                                 size= size, rotation=0.,\n",
    "                                 ha=\"left\", va=\"center\", color = 'black',\n",
    "\n",
    "                                 )\n",
    "                y_step+=1\n",
    "        else:\n",
    "            \n",
    "            if(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step]<0.01):\n",
    "                \n",
    "                    plt.text(df.sort_values('Estimate', ascending=False)['Estimate'].iloc[y_step]+0.005, y_step, \n",
    "                                     '**',\n",
    "                                     size= size, rotation=0.,\n",
    "                                     ha=\"left\", va=\"center\", color = 'black',\n",
    "\n",
    "                                     )\n",
    "            elif(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step]>= 0.01 and df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step]<0.05):\n",
    "                  \n",
    "                    plt.text(df.sort_values('Estimate', ascending=False)['Estimate'].iloc[y_step]+0.005, y_step, \n",
    "                                     '*',\n",
    "                                     size= size, rotation=0.,\n",
    "                                     ha=\"left\", va=\"center\", color = 'black',\n",
    "\n",
    "                                     )  \n",
    "            else:\n",
    "                    plt.text(df.sort_values('Estimate', ascending=False)['Estimate'].iloc[y_step]+0.005, y_step, \n",
    "                                     ' ',\n",
    "                                     size= size, rotation=0.,\n",
    "                                     ha=\"left\", va=\"center\", color = 'black',\n",
    "\n",
    "                                     )    \n",
    "\n",
    "            y_step+=1\n",
    "            \n",
    "         \n",
    "    text_diff =xlim[1]\n",
    "    #coef_SVR_tot.loc['R-squared', 'value']\n",
    "    f_prob = '(ns)'\n",
    "    if(regression_model.loc['F-pvalue', 'value']<0.01):\n",
    "        f_prob = '(**)'\n",
    "    elif(regression_model.loc['F-pvalue', 'value']<0.05):\n",
    "        f_prob = '(*)'\n",
    "        \n",
    "    \n",
    "    plot_ci = np.round(regression_model.loc['CI', 'value'],2)\n",
    "    \n",
    "    plt.text(xlim[1] - 0.05*xlim[1], df.shape[0]- 0.25*df.shape[0],\n",
    "             r'$ R^2 = $' + str(np.round(regression_model.loc['R-squared', 'value'],2))+ '\\n$CI = $' + str(plot_ci) + '\\n$F^2 = $' + str(np.round(regression_model.loc['F-squared', 'value'],2)) + ' ' + '\\n$F = $' + str(np.round(regression_model.loc['F', 'value'],2)) + '\\n$P (F) = $' + f_prob,\n",
    "                             size= 12, rotation=0.,\n",
    "                             ha=\"right\", va=\"center\", color = 'black',\n",
    "                             bbox=dict(boxstyle=\"round\",\n",
    "                                       ec='gray',\n",
    "                                        fc='gray',\n",
    "                                       )\n",
    "                             )\n",
    "\n",
    "    plt.xticks(fontsize=10)\n",
    "    plt.yticks(fontsize=10)\n",
    "    \n",
    "    plt.xlabel('Estimate', fontsize=12)\n",
    "    plt.ylabel('Features', fontsize=12)\n",
    "    plt.locator_params(axis='x', nbins=4)\n",
    "    \n",
    "\n",
    "def plot_evolution(dict_Df, i, X_cat_, xlim = [0,25], size = 10):\n",
    "\n",
    "    fp_value = dict_Df[i][1]\n",
    "    fp_value_fdr = dict_Df[i][2]\n",
    "    coef_df_ = dict_Df[i][0]\n",
    "\n",
    "\n",
    "    title = 'iter:' + str(i) + '\\n'\n",
    "    title += '|    f-pva: (' + str(np.min(fp_value).round(3)) + ' ; ' + str(np.mean(fp_value).round(3)) + ' ; ' + str(np.max(fp_value).round(3)) + ' ; ' + str(np.median(fp_value).round(3)) + ') |\\n'\n",
    "    title += '|  fdr-pva: (' + str(np.min(fp_value_fdr).round(3)) + ' ; ' + str(np.mean(fp_value_fdr).round(3)) + ' ; ' + str(np.max(fp_value_fdr).round(3)) + ' ; ' + str(np.median(fp_value_fdr).round(3)) + ') |'\n",
    "\n",
    "\n",
    "\n",
    "    coef_df_ = coef_df_.sort_values('Estimate', ascending=False)\n",
    "    \n",
    "    bar_color = get_bar_colors(coef_df_, X_cat_)\n",
    "    plt.title(title)\n",
    "    sns.barplot(x=\"Estimate\", y=\"Features\", data = coef_df_, xerr=coef_df_['Estimate std'], palette =bar_color)\n",
    "    plt.xlim(xlim);\n",
    "\n",
    "    y_step=0 \n",
    "    for j in range(coef_df_.shape[0]):\n",
    "        if(coef_df_['p value'].iloc[y_step]<0.01):\n",
    "\n",
    "            plt.text(coef_df_['Estimate'].iloc[y_step]+0.005, y_step, \n",
    "                                             '**',\n",
    "                                             size= size, rotation=0.,\n",
    "                                             ha=\"left\", va=\"center\", color = 'black',\n",
    "\n",
    "                                             )\n",
    "        elif(coef_df_['p value'].iloc[y_step]>= 0.01 and df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step]<0.05):\n",
    "\n",
    "            plt.text(coef_df_['Estimate'].iloc[y_step]+0.005, y_step, \n",
    "                                             '*',\n",
    "                                             size= size, rotation=0.,\n",
    "                                             ha=\"left\", va=\"center\", color = 'black',\n",
    "\n",
    "                                             )  \n",
    "        else:\n",
    "            plt.text(coef_df_['Estimate'].iloc[y_step]+0.005, y_step, \n",
    "                                             ' ',\n",
    "                                             size= size, rotation=0.,\n",
    "                                             ha=\"left\", va=\"center\", color = 'black',\n",
    "\n",
    "                                             )    \n",
    "\n",
    "        y_step+=1\n",
    "        \n",
    "        \n",
    "    \n",
    "def SearchBestModel(case_x, case_y, case_x_for_strat):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(case_x, case_y, test_size=.30, stratify=case_x_for_strat, random_state=1)\n",
    "\n",
    "    opt_SVR = BayesSearchCV(\n",
    "            SVR(),\n",
    "            {\n",
    "                #'gamma': ( 0.0001, 0.01, 0.001, 0.1, 1, 10),\n",
    "                'kernel': ['rbf'],\n",
    "                'degree': (3, 4, 5, 6),\n",
    "                #'tol:' : (1e-6, 1e-3, 1e+1),\n",
    "                #'n_estimators': (100, 1000),\n",
    "\n",
    "            },\n",
    "            n_iter=10,\n",
    "            cv=3, random_state=1\n",
    "        )\n",
    "\n",
    "    opt_SVR.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    print('SVR')\n",
    "    print(\"val. score: %s\" % opt_SVR.best_score_)\n",
    "    print(\"test score: %s\" % opt_SVR.score(X_test, y_test))\n",
    "    print(\"best parameters: %s\" % str(opt_SVR.best_params_))\n",
    "    print('---------------------------------------------\\n')\n",
    "    \n",
    "    return opt_SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582301b8",
   "metadata": {},
   "source": [
    "## Colors, variables names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25aade46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat = pd.read_csv('../Data/var_name_color_code.csv', encoding='latin-1', sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b59fdf6",
   "metadata": {},
   "source": [
    "## Load Data and z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe20f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = pd.read_excel('../Data/Roi_GM_Base.xlsx', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a404099",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_z_score = data_.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b395415",
   "metadata": {},
   "outputs": [],
   "source": [
    "colunm = 'diagnosis_specify'\n",
    "cn_col = conn_z_score[colunm]\n",
    "\n",
    "conn_z_score[colunm] = conn_z_score[colunm].apply(lambda x: (x-cn_col.mean())/ cn_col.std())\n",
    "\n",
    "colunm = 'country_class'\n",
    "cn_col = conn_z_score[colunm]\n",
    "\n",
    "conn_z_score[colunm] = conn_z_score[colunm].apply(lambda x: (x-cn_col.mean())/ cn_col.std())\n",
    "\n",
    "colunm = 'Edad_procesada'\n",
    "cn_col = conn_z_score[colunm]\n",
    "\n",
    "conn_z_score[colunm] = conn_z_score[colunm].apply(lambda x: (x-cn_col.mean())/ cn_col.std())\n",
    "\n",
    "colunm = 'years_education'\n",
    "cn_col = conn_z_score[colunm]\n",
    "\n",
    "conn_z_score[colunm] = conn_z_score[colunm].apply(lambda x: (x-cn_col.mean())/ cn_col.std())\n",
    "\n",
    "colunm = 'cognition_general_score'\n",
    "cn_col = conn_z_score[colunm]\n",
    "\n",
    "conn_z_score[colunm] = conn_z_score[colunm].apply(lambda x: (x-cn_col.mean())/ cn_col.std())\n",
    "\n",
    "colunm = 'executive_score'\n",
    "cn_col = conn_z_score[colunm]\n",
    "\n",
    "conn_z_score[colunm] = conn_z_score[colunm].apply(lambda x: (x-cn_col.mean())/ cn_col.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff54282",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_z_score = conn_z_score.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5181bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_z_score.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f3a29a",
   "metadata": {},
   "source": [
    "### RSNs mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e5f818",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_z_score['p_SN'] = conn_z_score[SN].sum(axis=1) / len(SN)\n",
    "conn_z_score['p_DMN'] = conn_z_score[DMN].sum(axis=1) / len(DMN)\n",
    "conn_z_score['p_EN'] = conn_z_score[EN].sum(axis=1) / len(EN)\n",
    "conn_z_score['p_VN'] = conn_z_score[VN].sum(axis=1) / len(VN)\n",
    "conn_z_score['p_MN'] = conn_z_score[MN].sum(axis=1) / len(MN)\n",
    "\n",
    "best= ['p_SN', 'p_DMN', 'p_EN', 'p_VN', 'p_MN'] # Definidio en la celda 1\n",
    "best = best + [ 'Promedio_traslacion', 'Promedio_rotacion', 'DMN', 'EN', 'MN', 'SN', 'VN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c65623",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(['p_SN', 'p_DMN', 'p_EN', 'p_VN', 'p_MN'])):\n",
    "    idx = len(X_cat)\n",
    "    X_cat.loc[idx, :] = [best[i], 'GMF', 'GM Factor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8ea4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(['Promedio_traslacion', 'Promedio_rotacion'])):\n",
    "    idx = len(X_cat)\n",
    "    X_cat.loc[idx, :] = [best[i], 'FP', 'Functional Problems']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14d0afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(['DMN', 'EN', 'MN', 'SN', 'VN'])):\n",
    "    idx = len(X_cat)\n",
    "    X_cat.loc[idx, :] = [best[i], 'FF', 'Functional Features']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a0074f",
   "metadata": {},
   "source": [
    "### Demographics, cognition, GM, functional connectivity and motion artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed93b43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_z_score_fer = conn_z_score.drop([              'mini_sea_tom', 'mini_sea_total'], axis =1 )\n",
    "conn_z_score_tom = conn_z_score.drop(['mini_sea_fer',                 'mini_sea_total'], axis =1 )\n",
    "conn_z_score_tot = conn_z_score.drop(['mini_sea_fer', 'mini_sea_tom',                 ], axis =1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00e373b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_z_score_fer.dropna(inplace=True)\n",
    "conn_z_score_tom.dropna(inplace=True)  \n",
    "conn_z_score_tot.dropna(inplace=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f576744",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(conn_z_score_fer.shape,\n",
    "conn_z_score_tom.shape,  \n",
    "conn_z_score_tot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7675d060",
   "metadata": {},
   "outputs": [],
   "source": [
    "## y data\n",
    "y_2A_fer = conn_z_score_fer['mini_sea_fer']\n",
    "y_2A_tom = conn_z_score_tom['mini_sea_tom']\n",
    "y_2A_tot = conn_z_score_tot['mini_sea_total']\n",
    "\n",
    "\n",
    "\n",
    "## x data\n",
    "X_2A_fer = conn_z_score_fer.drop(['mini_sea_fer'], axis =1 )\n",
    "X_2A_tom = conn_z_score_tom.drop(['mini_sea_tom'], axis =1 )\n",
    "X_2A_tot = conn_z_score_tot.drop(['mini_sea_total'], axis =1 )\n",
    "\n",
    "best_w_cog = list(best)\n",
    "best_w_cog.extend(['Edad_procesada', 'years_education', 'diagnosis_specify', 'country_class','cognition_general_score', 'executive_score', 'gender'])\n",
    "best_w_cog = np.array(best_w_cog)\n",
    "\n",
    "\n",
    "X_2A_fer = X_2A_fer[best_w_cog]\n",
    "X_2A_tom = X_2A_tom[best_w_cog]\n",
    "X_2A_tot = X_2A_tot[best_w_cog]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39519e9e",
   "metadata": {},
   "source": [
    "### Boostrapping and Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47469c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "case2A_fer_for_strat =  y_2A_fer.copy()\n",
    "median = case2A_fer_for_strat.median()\n",
    "case2A_fer_for_strat.loc[case2A_fer_for_strat<median]= 0\n",
    "case2A_fer_for_strat.loc[case2A_fer_for_strat>=median]=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3c719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "case2A_tom_for_strat =  y_2A_tom.copy()\n",
    "median = case2A_tom_for_strat.median()\n",
    "case2A_tom_for_strat.loc[case2A_tom_for_strat<median]= 0\n",
    "case2A_tom_for_strat.loc[case2A_tom_for_strat>=median]=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6f11f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "case2A_tot_for_strat =  y_2A_tot.copy()\n",
    "median = case2A_tot_for_strat.median()\n",
    "case2A_tot_for_strat.loc[case2A_tot_for_strat<median]= 0\n",
    "case2A_tot_for_strat.loc[case2A_tot_for_strat>=median]=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5de331f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_2A_fer_classic_reg = X_2A_fer\n",
    "\n",
    "run = True\n",
    "\n",
    "coef_SVR_fer_dir_2A = {}\n",
    "\n",
    "\n",
    "run_count = 0\n",
    "while run:\n",
    "    coef_SVR_fer = boostrapping(X_2A_fer_classic_reg, y_2A_fer, case2A_fer_for_strat, list(X_2A_fer_classic_reg.columns))\n",
    "    \n",
    "    coef_SVR_fer_dir_2A[run_count] = coef_SVR_fer\n",
    "    \n",
    "    run_count+=1\n",
    "    \n",
    "    df = coef_SVR_fer[0]\n",
    "    df.index.name = 'Features'\n",
    "    df = df.iloc[1:-5, 0:-1]\n",
    "\n",
    "    df = df.reset_index()\n",
    "    data = df.sort_values('p value', ascending=False)\n",
    "    data\n",
    "\n",
    "    feat_remove = data.iloc[0,0]\n",
    "        \n",
    "    if(X_2A_fer_classic_reg.shape[1]<=8 or data.iloc[0,3] < 0.05 or coef_SVR_fer[0].loc['F-pvalue', 'value'] < 0.05):\n",
    "        run = False\n",
    "    else:\n",
    "        X_2A_fer_classic_reg = X_2A_fer_classic_reg.drop([feat_remove], axis=1)\n",
    "        print(feat_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa22954",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_2A_tom_classic_reg = X_2A_tom\n",
    "\n",
    "run = True\n",
    "\n",
    "coef_SVR_tom_dir_2A = {}\n",
    "\n",
    "\n",
    "run_count = 0\n",
    "while run:\n",
    "    coef_SVR_tom = boostrapping(X_2A_tom_classic_reg, y_2A_tom, case2A_tom_for_strat, list(X_2A_tom_classic_reg.columns))\n",
    "    \n",
    "    coef_SVR_tom_dir_2A[run_count] = coef_SVR_tom\n",
    "    \n",
    "    run_count+=1\n",
    "    \n",
    "    df = coef_SVR_tom[0]\n",
    "    df.index.name = 'Features'\n",
    "    df = df.iloc[1:-5, 0:-1]\n",
    "\n",
    "    df = df.reset_index()\n",
    "    data = df.sort_values('p value', ascending=False)\n",
    "    data\n",
    "\n",
    "    feat_remove = data.iloc[0,0]\n",
    "        \n",
    "    if(X_2A_tom_classic_reg.shape[1]<=8 or data.iloc[0,3] < 0.05 or coef_SVR_tom[0].loc['F-pvalue', 'value'] < 0.05):\n",
    "        run = False\n",
    "    else:\n",
    "        X_2A_tom_classic_reg = X_2A_tom_classic_reg.drop([feat_remove], axis=1)\n",
    "        print(feat_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404c68b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_2A_tot_classic_reg = X_2A_tot\n",
    "\n",
    "run = True\n",
    "\n",
    "coef_SVR_tot_dir_2A = {}\n",
    "\n",
    "\n",
    "run_count = 0\n",
    "while run:\n",
    "    coef_SVR_tot = boostrapping(X_2A_tot_classic_reg, y_2A_tot, case2A_tot_for_strat, list(X_2A_tot_classic_reg.columns))\n",
    "    \n",
    "    coef_SVR_tot_dir_2A[run_count] = coef_SVR_tot\n",
    "    \n",
    "    run_count+=1\n",
    "    \n",
    "    df = coef_SVR_tot[0]\n",
    "    df.index.name = 'Features'\n",
    "    df = df.iloc[1:-5, 0:-1]\n",
    "\n",
    "    df = df.reset_index()\n",
    "    data = df.sort_values('p value', ascending=False)\n",
    "    data\n",
    "\n",
    "    feat_remove = data.iloc[0,0]\n",
    "        \n",
    "    if(X_2A_tot_classic_reg.shape[1]<=8 or data.iloc[0,3] < 0.05 or data.iloc[0,3] < 0.05 or coef_SVR_tot[0].loc['F-pvalue', 'value'] < 0.01):\n",
    "        run = False\n",
    "    else:\n",
    "        X_2A_tot_classic_reg = X_2A_tot_classic_reg.drop([feat_remove], axis=1)\n",
    "        print(feat_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c504261",
   "metadata": {},
   "source": [
    "### Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235935c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "key_list_fer = sorted(list(coef_SVR_fer_dir_2A.keys()))\n",
    "\n",
    "list_features_fer = list(coef_SVR_fer_dir_2A[key_list_fer[-1]][0].index)\n",
    "list_features_fer.remove('_intercept', )\n",
    "list_features_fer.remove('R-squared')\n",
    "list_features_fer.remove('CI')\n",
    "list_features_fer.remove('F-squared')\n",
    "list_features_fer.remove('F')\n",
    "list_features_fer.remove('F-pvalue')\n",
    "\n",
    "\n",
    "dict_Df_fer = {}\n",
    "for i in key_list_fer:\n",
    "\n",
    "    coef_df_fer = pd.DataFrame(\n",
    "                index=list_features_fer,\n",
    "                columns=['Estimate', 'p value', 'Estimate std']\n",
    "            )\n",
    "\n",
    "    for j in list_features_fer:\n",
    "\n",
    "        coef_df_fer.loc[j, 'Estimate'] = coef_SVR_fer_dir_2A[i][0].loc[j, 'Estimate']\n",
    "        coef_df_fer.loc[j, 'p value'] = coef_SVR_fer_dir_2A[i][0].loc[j, 'p value']\n",
    "        coef_df_fer.loc[j, 'Estimate std'] = coef_SVR_fer_dir_2A[i][0].loc[j, 'Estimate std']\n",
    "\n",
    "\n",
    "        \n",
    "    coef_df_fer.index.name = 'Features'\n",
    "    coef_df_fer = coef_df_fer.reset_index()\n",
    "    dict_Df_fer[i] = [coef_df_fer, coef_SVR_fer_dir_2A[i][2], coef_SVR_fer_dir_2A[i][3][1]]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade4a611",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_list_tom = sorted(list(coef_SVR_tom_dir_2A.keys()))\n",
    "\n",
    "list_features_tom = list(coef_SVR_tom_dir_2A[key_list_tom[-1]][0].index)\n",
    "list_features_tom.remove('_intercept', )\n",
    "list_features_tom.remove('R-squared')\n",
    "list_features_tom.remove('CI')\n",
    "list_features_tom.remove('F-squared')\n",
    "list_features_tom.remove('F')\n",
    "list_features_tom.remove('F-pvalue')\n",
    "\n",
    "\n",
    "dict_Df_tom = {}\n",
    "for i in key_list_tom:\n",
    "\n",
    "    coef_df_tom = pd.DataFrame(\n",
    "                index=list_features_tom,\n",
    "                columns=['Estimate', 'p value', 'Estimate std']\n",
    "            )\n",
    "\n",
    "    for j in list_features_tom:\n",
    "\n",
    "        coef_df_tom.loc[j, 'Estimate'] = coef_SVR_tom_dir_2A[i][0].loc[j, 'Estimate']\n",
    "        coef_df_tom.loc[j, 'p value'] = coef_SVR_tom_dir_2A[i][0].loc[j, 'p value']\n",
    "        coef_df_tom.loc[j, 'Estimate std'] = coef_SVR_tom_dir_2A[i][0].loc[j, 'Estimate std']\n",
    "\n",
    "\n",
    "        \n",
    "    coef_df_tom.index.name = 'Features'\n",
    "    coef_df_tom = coef_df_tom.reset_index()\n",
    "    dict_Df_tom[i] = [coef_df_tom, coef_SVR_tom_dir_2A[i][2], coef_SVR_tom_dir_2A[i][3][1]]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aea449",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_list_tot = sorted(list(coef_SVR_tot_dir_2A.keys()))\n",
    "\n",
    "list_features_tot = list(coef_SVR_tot_dir_2A[key_list_tot[-1]][0].index)\n",
    "list_features_tot.remove('_intercept', )\n",
    "list_features_tot.remove('R-squared')\n",
    "list_features_tot.remove('CI')\n",
    "list_features_tot.remove('F-squared')\n",
    "list_features_tot.remove('F')\n",
    "list_features_tot.remove('F-pvalue')\n",
    "\n",
    "\n",
    "dict_Df_tot = {}\n",
    "for i in key_list_tot:\n",
    "\n",
    "    coef_df_tot = pd.DataFrame(\n",
    "                index=list_features_tot,\n",
    "                columns=['Estimate', 'p value', 'Estimate std']\n",
    "            )\n",
    "\n",
    "    for j in list_features_tot:\n",
    "\n",
    "        coef_df_tot.loc[j, 'Estimate'] = coef_SVR_tot_dir_2A[i][0].loc[j, 'Estimate']\n",
    "        coef_df_tot.loc[j, 'p value'] = coef_SVR_tot_dir_2A[i][0].loc[j, 'p value']\n",
    "        coef_df_tot.loc[j, 'Estimate std'] = coef_SVR_tot_dir_2A[i][0].loc[j, 'Estimate std']\n",
    "\n",
    "\n",
    "        \n",
    "    coef_df_tot.index.name = 'Features'\n",
    "    coef_df_tot = coef_df_tot.reset_index()\n",
    "    dict_Df_tot[i] = [coef_df_tot, coef_SVR_tot_dir_2A[i][2], coef_SVR_tot_dir_2A[i][3][1]]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4589df",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b836a521",
   "metadata": {},
   "outputs": [],
   "source": [
    "#coef_SVR_fer_dir_2A[fer_2A_keys[-1]][0].to_excel('Results/Fig_2_panel_3/fer.xlsx')\n",
    "#coef_SVR_fer_tom_2A[fer_2A_keys[-1]][0].to_excel('Results/Fig_2_panel_3/tom.xlsx')\n",
    "#coef_SVR_fer_tot_2A[fer_2A_keys[-1]][0].to_excel('Results/Fig_2_panel_3/tot.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434b11b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "375.199px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
